{
  "hash": "87082765dbf83ae5039155e022c6f5e0",
  "result": {
    "markdown": "---\ntitle: \"Restricciones a la aleatorización\"\nauthor: [\"Miguel Equihua\", \"Alan Aguirre\"]\ndate: \"2023-02-1\"\ndraft: false\nlang: es\ncategories: [clase]\nformat:\n  html:\n    code-fold: true\n---\n\n\n![](images/2012-AJ-12-10.jpg){width=\"500\"}\n\n### Restricciones a la aleatorización\n\nImaginemos que tenemos las dos situaciones experimentales que se ilustran en la figura. El análisis de estas situaciones experimentales sugiere dos posible aproximaciones, aproximaciones prácticas, pero\n\n[**¿qué modelos propondrías para analizarlos?**]{style=\"color:GoldenRod\"}\n\n![](images/retricciones_a_la_aleatorizaci%C3%B3n_1.png)\n\nSi se supone ausencia de interacción entre Z y β, ambos casos se podría analizar con el mismo modelo:\n\n$$\ny_{ij} = \\mu + Z_{i} + B_{j} + \\varepsilon_{(ij)}\n$$\n\nEn donde: \\* $\\mu$ es la media general \\* $Z_{i}$ es el efecto del tratamiento $i,\\dots, t$ \\* $B_{j}$ es el efecto del tratamiento $j,\\dots, b$ \\* $\\varepsilon_{(ij)}$ es el error aleatorio\n\n### Errores de restricción a la aleatorización\n\nAnderson (1970, 1974) notó que no podía ser que el mismo modelo fuera apropiado para dos situaciones tan distintas. Razonó que no se podían hacer inferencias sobre los **bloques** pues cada uno de ellos aparece sólo una vez.\n\n[**¿Concuerdas en que no es posible estimar su efecto?**]{style=\"color:GoldenRod\"}\n\n[**¿Cuál es el efecto de restringir la aleatorización en la asignación de los tratamientos?**]{style=\"color:GoldenRod\"}.\n\nAnderson propuso incorporar en el modelo términos que dieran cuenta de restricciones en la aleatorización de las unidades experimentales. Llamó a estos términos \"errores de restricción\", pues también sugirió que deberían ser considerados términos de *efectos aleatorios*.\n\nAsí, el modelo de bloques se escribiría así:\n\n$$\ny_{ijkm} = \\mu + Z_{i} + B_{j} + \\delta_{k(j)} + \\varepsilon_{m(ijk)}\n$$\n\nEn donde los términos tienen la misma interpretación de arriba, y lo que aregamoses:\n\n-   $\\delta_{k(j)}$ , el componente de variación aleatoria introducido por la restricción a la aleatorización al formar bloques. Este error por lo pronto no es estimable.\n\n-   $\\varepsilon_{m(ijk)}$ es el componente aleatorio derivado de la precisión de las mediciones.\n\nEl *error de restricción de bloques* representa las características particulares y aleatorias de cada conjunto de unidades que formen el bloque *j* (cosas como errores de medición, condiciones ambientales peculiares del bloque pero comunes en su interior, manipulación común al iinterior del bloque, etc.). Este nuevo término tiene estas características:\n\n-   Es aleatorio (se asume se distribuye como una normal e independientemente: \\~normal(0, $\\sigma_{k}^2$)\n-   No es estimable y tampoco lo son sus combinaciones, porque no hay grados de libertad.\n-   Es útil en el modelo para facilitar identificar qué efectos se pueden poner a prueba mediante razones *F*. Esto se determina al examinar las *esperanzas de cuadrados medios* (**ECM**).\n-   Es un *efecto confundido* (no se puede separar) del efecto de bloque o grupo de unidades experimentales.\n\nConsideremos el caso de la ganancia de peso en un grupo de orugas que declina conforme se incrementa el contenido de taninos en su dieta, esta condición puede describirse en forma abreviada así:\n\nganancia de peso de cada oruga = ganancia de peso base en general + efecto del contenido de taninos en la dieta + Efecto de otros factores que fluctúan aleatoriamente\n\n¿Cómo se ve el análisis del modelo en un cuadro de ANOVA?\n\n![](images/Anova_caso_1.png)\n\n[¿Qué tipo de efecto tienen los factores? ¿Qué se puede probar comparando cuadrados medios?]{style=\"color:GoldenRod\"}\n\nCon la propuesta de Anderson de incluir términos para representar el efecto de no aplicar aleatorización en forma completa, el cuadro de ANOVA se vería como se muestra enseguida.\n\n[¿Qué tipo de efecto tienen los factores? ¿Qué se puede probar]{style=\"color:GoldenRod\"}\n\n![](Images/Anova_Anderson.png)\n\nLa idea de Anderson tiene validez general para experimentos *completos y balanceados*. Se puede utilizar para analizar con claridad el efecto de distintos arreglos experimentales que puedan interesar al investigador.\n\n#### Ejemplo de aplicación del error de restricción en la planeación de experimentos\n\n![](images/becerro.jpg)\n\nSe quieren probar 3 tipos de *ración de alimentación* (**A**, **B**, **C**), sobre el desempeño de vacas de la raza Holstein. Se dispone de 12 animales para realizar el ensayo. Se cuenta con corrales en los que caben hasta 4 animales en cada uno. Podemos optar por dar un tratamiento de alimentación a cada corral.\n\n![](Images/Dise%C3%B1o_vacas_1.png)\n\n[¿Consideras que hay algún inconvenientes en esta situación experimental?]{style=\"color:GoldenRod\"}\n\nEl modelo que razonablemente describe esta situación sería:\n\n$$\nY_{ijk} =  \\mu + T_{i} + \\delta_{k(i)} + \\varepsilon_{j(ik)}\n$$\n\nEl cuadro de ANOVA se vería así:\n\n![](Images/ANOVA_Modelo_vacas_1.png)\n\n[¿Qué piensan de este otro arreglo experimental?]{style=\"color:GoldenRod\"}\n\n![](Images/Dise%C3%B1o_vacas_2.png)\n\nEl modelo es el mismo que en la situación, pero ahora varían los términos estimables:\n\n$$\nY_{ijk} =  \\mu + T_{i} + \\delta_{k(i)} + \\varepsilon_{j(ik)}\n$$\n\nEl cuadro de ANOVA se vería así:\n\n![](Images/ANOVA_Modelo_vacas_2.png)\n\nComo [referencia sugerida encontré este artículo](http://www.scielo.org.co/pdf/rccp/v20n2/v20n2a11.pdf) que describe como hacer el análisis necesario para determinar las *esperanzas de cuadrados medios* (**EMC**).\n\n## Manos\n\nConsidera que estamos midiendo la mano izquierda y la derecha de varios individuos, las medidas están emparejadas dentro de cada individuo. Es decir, queremos controlar estadísticamente las diferencias entre individuos, así nos aseguramos que la mano izquierda del *individuo A* sea analizada en conjunto con la mano derecha del *individuo A*, ya que suponemos que alguien con una mano izquierda grande tendrá una mano derecha grande. Por lo tanto, la variable *Individuo* se incluirá en el modelo como una variable aleatoria. Se podría pensar que cada Individuo representa un **bloque** que incluye una medida para la mano izquierda y una medida para la mano derecha.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos <- read.table(\"manos.dat\", sep = \",\", header = T, stringsAsFactors = T)\nhead(manos)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Individual Hand Length\n1          A Left   17.5\n2          B Left   18.4\n3          C Left   16.2\n4          D Left   14.5\n5          E Left   13.5\n6          F Left   18.9\n```\n:::\n:::\n\n\n### Inspección de los datos\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(manos$Length, list(manos$Hand, manos$Individual), mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         A    B    C    D    E    F    G    H    I    J    K    L    M    N\nLeft  17.5 18.4 16.2 14.5 13.5 18.9 19.5 21.1 17.8 16.8 18.4 17.3 18.9 16.4\nRight 17.6 18.5 15.9 14.9 13.7 18.9 19.5 21.5 18.5 17.1 18.9 17.5 19.5 16.5\n         O    P\nLeft  17.5 15.0\nRight 17.4 15.6\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction.plot(manos$Individual,manos$Hand, manos$Length)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_1 <- lm(Length ~ 1, data = manos)\nsummary(manos_modelo_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Length ~ 1, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.975 -1.125  0.025  1.425  4.025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.4750     0.3415   51.16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.932 on 31 degrees of freedom\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_2 <- lm(Length ~ Hand, data = manos)\nsummary(manos_modelo_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Length ~ Hand, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.894 -1.109  0.075  1.306  3.906 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.3562     0.4900  35.418   <2e-16 ***\nHandRight     0.2375     0.6930   0.343    0.734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 30 degrees of freedom\nMultiple R-squared:  0.003899,\tAdjusted R-squared:  -0.0293 \nF-statistic: 0.1174 on 1 and 30 DF,  p-value: 0.7342\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_3 <- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.43125    0.14440 120.714  < 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,\tAdjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(manos_modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(>F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_4 <- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.43125    0.14440 120.714  < 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,\tAdjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(manos_modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(>F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## Qué tanto tiempo puede \"correr\" un experimento\n\nCuando Fisher concibió hacer experimentos en la estación experimental de Rothamsted en Inglaterra, recurriendo al auxilio del enfoque estadístico que él y otros investigadores de la época idearon, pensaban a largo plazo. [Encontré este documento que podría ser de su interés](https://repository.cimmyt.org/bitstream/handle/10883/18146/56637_2017_IX%2840%29.pdf?sequence=112&isAllowed=y). La estación experimental tiene disponiible los datos de estos experimentos. Por ejemplo [Este \"dataset\"](https://www.era.rothamsted.ac.uk/dataset/rbk1/01-FISHER1921) son los rendimientos anuales de trigo de \"parcelas selectas\" del experimento de trigo que aún hoy corren en Broadbalk . La serie tiene los datos de 1852-1918, tal y como los usó R.A. Fisher para su artículo de 1921 'Studies in crop variation'.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}