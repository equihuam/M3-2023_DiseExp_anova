[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca del módulo III",
    "section": "",
    "text": "El módulo III se ocupa de las nociones básicas de diseño de experimentos y las técnicas estadísticas utilizadas para analizarlos: El Análisis de Varianza (Andeva o Anova).\nSe reúnen aquí los documentos y código en R utilizados como apoyo audiovisual en clase."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M3 - Diseño de Experimentos",
    "section": "",
    "text": "Modelos de Efectos Mixtos\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n3 feb 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nModelos anidados\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n2 feb 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nRestricciones a la aleatorización\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n1 feb 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nDiagramas Causales\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n30 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nExperimentos completamente aleatorizados\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n30 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nEl Modelo estadístico lineal\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n28 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nConceptos y Modelos en la experimentación\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n27 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nLeyes de la Ciencia\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n26 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nBienvenidos al Módulo III de estadística\n\n\n\n\n\n\n\nanuncios\n\n\n\n\n\n\n\n\n\n\n\n25 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\n  \n\n\n\n\nEvaluación\n\n\n\n\n\n\n\nanuncios\n\n\n\n\n\n\n\n\n\n\n\n25 ene 2023\n\n\nMiguel Equihua, Alan Aguirre\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/bienvenida/index.html",
    "href": "posts/bienvenida/index.html",
    "title": "Bienvenidos al Módulo III de estadística",
    "section": "",
    "text": "Esta es la presentación del módulo III. Durante las últimas semanas revisaron conceptos de probabilidad y matemáticas, que necesitamos como un lenguaje eficiente de comunicación. También empezaron a explorar como es que se pueden analizar proposiciones sobre la existencia de asociación o incluso relaciones de dependencia entre dos variables: modelos de regresión simple. Ahora vamos aplicar y extender estos aprendizajes para abordar el desafío de producir conocimiento que nos permita comprender como funciona el mundo.\nUtilizaremos el lenguaje de programación R como plataforma de cómputo para el análisis de datos. Aspiiramos a ofrecerles así un curso introductorio para su uso. También nos interesa acercarnos a los enfoques formales para el análisis causal actual, mediante la formulación de Grafos Acíclicos Dirigidos (DAG). Los invitamos a dibujar las relaciones causales de sus proyectos para comprenderlas, comunicarlas y analizarlas con mayor eficiencia."
  },
  {
    "objectID": "posts/bienvenida/index.html#plan-de-clase",
    "href": "posts/bienvenida/index.html#plan-de-clase",
    "title": "Bienvenidos al Módulo III de estadística",
    "section": "Plan de clase",
    "text": "Plan de clase\nLas charlas previstas son las siguientes\n\n\n\n\n\n\n\nDía\nTema\n\n\nJueves 26\nUn lenguaje para describir modelos (diseño de experimentos y de tratamientos)\n\n\nViernes 27\nCausalidad y modelación gráfica: Grafos Acíclicos Dirigidos (DAG)\n\n\nLunes 30\nDiseño de experimentos: hipótesis y la modelación estadística\n\n\nMartes 31\nEfectos fijos y aleatorios sus implicaciones en los modelos estadísticos\n\n\nMiércoles 1 febrero\nEvitar confusión por variables conocidas: Bloques aleatorizados\n\n\nJueves 2\nMuestreo dentro unidades experimentales: Diseños anidados\n\n\nViernes 3\nUnidades experimentales múltinivel y anidadas: Diseños de Parcelas divididas\n\n\nLunes 6\nModelos jerárquicos (incluye medidas repetidas)\n\n\nMartes 7\n“Feria del diseño” para discutir los protocolos de los estudiantes"
  },
  {
    "objectID": "posts/concepto-y-modelos-experimentar/index.html",
    "href": "posts/concepto-y-modelos-experimentar/index.html",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "",
    "text": "McElreath (2020) presenta en su libro el hipotético ejemplo de la prueba de sangre para vampirismo. Propone que hay un análisis de sangre que detecta correctamente 95% de las veces, la afiliación de un individuo al linaje del conde Drácula y los inmortales vampiros. En notación matemática:\n\\[\n{Pr(resultado~ positivo~de~la~prueba|vampiro) = 0.95}\n\\]\nEs una prueba muy precisa, casi siempre identificando vampiros reales. Sin embargo, también comete errores y produce falsos positivos. Es así que el uno por ciento de las veces diagnostica incorrectamente a los simples mortales como vampiros:\n\\[\n{Pr(resultado~positivo~de~la~prueba|mortal) = 0.01}\n\\]\nLa última pieza de información que necesitamos es saber que los vampiros en realidad son bastante raros. Sólo el 0.1% de la población lo es, lo que implica:\n\\[\n{Pr(vampiro) = 0.001}\n\\]\nA partir de este conocimiento científico, supongamos que un amigo da positivo en el test de vampirismo.\n¿Cuál es la probabilidad de que sea un inmortal chupasangre ?\nEl enfoque de investigación formal empezaría por usar el teorema de Bayes para deducir la probabilidad \\({Pr(vampiro|positivo)}\\), lo que en cierta forma implica “invertir la probabilidad”, pues lo que ahora sabemos es el valor de \\({Pr(positivo|vampiro)}\\). El cálculo puede presentarse como:\n\\[\n\\Pr(vampiro|positivo) = \\frac{Pr(positivo|vampiro) \\times Pr(vampiro)}{Pr(positivo)}\n\\]\nen donde \\({Pr(positivo)}\\) es la probabilidad promedio de los resultados positivos de la prueba, es decir,\n\\[\nPr(positivo) = Pr(positivo|vampiro)\\times Pr(vampiro) + Pr(positivo|mortal) \\times ({1 − Pr(vampiro)})\n\\]\nTodo esto lo podemos hacer en R.\nPrimero tomamos nota de lo que ya sabemos al principio, ¡a priori!\n\n\nCódigo\nPr_positivo_vampiro <- 0.95 \nPr_positivo_Mortal <- 0.01 \nPr_vampiro <- 0.001 \n\n\nTomamos la fórmula de Bayes para invertir la probabilidad, pues queremos saber qué está pasando cuando tenemos la fortuna de toparnos con un resultado positivo en la prueba de sangre:\n\\[\nPr(positivo|vampiro)\n\\]\nEsto equivale a preguntarnos, dado que ya vimos el resultado científico que significa la prueba de sangre, ¿será vampiro el sujeto de quien se obtuvo esa muestra?:\n\\[\nPr(vampiro|positivo)\n\\]\n\n\nCódigo\nPr_positivo <- Pr_positivo_vampiro * Pr_vampiro + Pr_positivo_Mortal * (1 - Pr_vampiro) \n\nPr_vampiro_positivo <- (Pr_positivo_vampiro * Pr_vampiro) / Pr_positivo\n\nround(Pr_vampiro_positivo, 3)\n\n\n[1] 0.087\n\n\nPor lo tanto, la probabilidad de que el amigo sea en realidad un vampiro es 8.7%.\n¿Encuentras este resultado afin o contrario a lo que pensabas antes de hacer los cálculos?\nEste es un resultado muy importante. Exactamente así, o algo muy parecido, es el procedimiento que se sigue en muchos contextos de prueba realistas: las pruebas de PCR, antígeno o anticuerpos para SarsCov-2, la prueba del VIH la del DNA en un perfil criminal y por supuesto la prueba de significancia estadística.\nQuizás ayude a mejorar la intuición que tenemos de las cosas el considerar que siempre que la condición de interés sea muy rara, desarrollar una prueba excelente, capaz de diagnosticar bien todos los casos verdaderos (aunque invitablemente produzca también algunos falsos positivos), no es garantía suficiente de que un resultado positivo en general conlleve mucha información.\nLa razón es que usualmente resulta inevitable tener falsos positivos y por simple aritmética, esos casos serán la mayoría de los resultados que tendremos, incluso si todos los verdaderos positivos fueran detectados correctamente.\nAunque, como dice McElreath, no hay nada particularmente bayesiano aqui. Podríamos pensar que la ecuación que usamos aquí salio de la nada, aunque quizás la recuerdes de algún curso previo, de alguna charla interesante por ahí o incluso de lo que viste con Rosario ¡hace unas semanas!\nQuizás el ejemplo puede verse en forma más intuitiva utilizando otra narrativa para comprender lo que está ocurriendo. Digamos que en lugar de informar sobre las probabilidades, como antes, te digo lo siguiente:\n\nEn una población de 100,000 personas, 100 de ellas son vampiros.\nDe los 100 que son vampiros 95 darán positivo en la prueba de vampirismo.\nDe los 99,900 simples mortales, 999 darán positivo a la prueba de vampirismo.\n\nAhora piensa en esto, si hacemos pruebas a las 100,000 personas, ¿qué proporción de los que dan positivo en las pruebas de vampirismo son realmente vampiros?\nMuchas personas, aunque ciertamente no todas, encuentran esta forma de contar la historia mucho más fácil. Sigamos por este camino.\n¿Qué tal si contamos el número de personas que dan positivo?:\n\\[\n95 + 999 = 1094\n\\] De estas 1094 pruebas positivas, 95 de ellas son vampiros reales, lo que nos lleva sencillamente a esto:\n\\[\nPr(vampiro|positivo) = \\frac{95}{1094} ≈ 0.087\n\\]\nEsta es exactamente la misma respuesta de 8.7% que encontramos antes. Pero no tuvimos que recordar la ´“formula mágica” de Bayes, nada más tuvimos que contar y pensar con calma.\nEsta forma de presentar el problema mediante el “conteo de los actores” en lugar de recurrir a probabilidades, suele denominarse formato de frecuencia o frecuencias naturales.\nLas razones propuestas para explicar el por qué el formato de frecuencia ayuda a la gente a intuir el enfoque correcto siguen siendo polémicas. Podría ser que de entrada sólo podemos encontrarnos con conteos en el mundo real. Quizás sea cierto que nadie ha visto nunca una probabilidad andando por ahí. Independientemente de la explicación de este fenómeno, podemos explotarlo.\nLos eventos muestreados en el análisis de las distribuciones de probabilidades de modelos estadísticos en algún análisis de datos, son los valores de los parámetros. La mayoría de los parámetros no tienen una “materialización” empírica exacta.\nEl formalismo bayesiano trata las distribuciones de los parámetros como una plausibilidad relativa, no como un proceso aleatorio que ocurre en el mundo físico. En cualquier caso, la aleatoriedad es siempre una propiedad de la información, nunca del mundo real.\n\n\n¿Podemos confiar en que la estadística nos proteja de la mala ciencia?.\nEl ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no podemos saberlo;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nDebemos/podemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr(señal~detectada|verdadero) =Pr(H|V) = 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr(señal~detectada|falso) = Pr(H|F) = 0.05}\\).\nEsa es la tasa de falsos positivos, se trata del, digamos 5%, de la prueba de significancia que usamos convencionalmente.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr(verdadero) = P(V) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nPara averiguar esto, calculamos la componente a posteriori:\n\\[\nPr(detectada|Hipótesis) = \\frac{Pr(Hipótesis|detectada) Pr(detectado)} {Pr(Hipótesis)} = \\\\\n\\\\\n\\frac{Pr(H|V) Pr(V)} {Pr(H|V) Pr(V) + Pr(H|F) Pr(F)}\n\\\\\n\\]\n\n\nCódigo\nPr_posterior_hallazgo_verdadero <- (0.95 * 0.01) / ((0.95 * 0.01) + (0.05 * (1-0.01)))\nPr_posterior_hallazgo_verdadero\n\n\n[1] 0.1610169\n\n\nComo podemos ver, al substituir los valores imaginados, encontramos que la respuesta es aproximadamente \\({Pr(V|H) = 0.16}\\).\nAsí que un resultado positivo corresponde a un 16% de probabilidad de que la hipótesis sea cierta.\nEste es el mismo fenómeno de baja tasa de base que se aplica en las pruebas médicas (y en nuestro ejemplo de vampiros).\nPuedes reducir la tasa de falsos positivos al 1% y ¿qué pasaría?\n\n\n\n\nUna manera de explorar esto es haciendo un escript, algorítmo o programa que nos permita automatizar una tarea repetitiva y potencialmente aburrida. Veamos como hacerlo.\n\n\nCódigo\nciencia <- function (pr_pos_verdadero = 0.95, pr_verdadero = 0.01)\n{\n    pr_falso <- 1 - pr_verdadero\n    pr_pos_falso <- 1 - pr_pos_verdadero\n\n    pr_verdadero_pos <- pr_pos_verdadero * pr_verdadero / (pr_pos_verdadero * pr_verdadero + pr_pos_falso*pr_falso)\n\n    return(pr_verdadero_pos)\n}\n\n\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\n\nCódigo\n# Elegimos una serie de valores de interés\nvalores_de_interés <- seq(0.9, 0.99, 0.01)\n\n# Creamos un espacio de memoria vacío para anotar ahí los cálculos\nresultados <- data.frame(numeric(0), numeric(0))\nfor (pr in valores_de_interés) \n    resultados <- rbind(resultados, c(pr, ciencia(pr, 0.01)))\n\nnames(resultados) <- c(\"p_error\", \"p_post\")\n\n\nAhora podemos ver los resultados del experimento con ayuda de una gráfica.\n\n\nCódigo\n# Área de graficación. mar() para el margen. oma() alrededor del margen.\npar(oma=c(2,3,1,2)) # abajo=2, izq=3, arriba=1, der=2\npar(mar=c(4,4,2,2) + 0.7)\n\n# Tamaño de la gráfica\noptions(repr.plot.width = 15, repr.plot.height = 5)\n\n# Gráfica\nplot(x = 1 - resultados$p_error, y = resultados$p_post,\n     type = \"b\", xlab = \"valor de P\", ylab = \"Pr post detección positiva\", \n     cex = 2, cex.axis  = 1, cex.lab = 2)\n\n\n\n\n\n\n\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, nos permite llevar la probabilidad posterior de descubrimientos exitosos hasta 0.5.\nApenas tan buena como el lanzamiento de una moneda.\nPodemos pensar que lo que hemos hecho hasta aquí es prácticamente un juego, pero ¿qué tan cercano podría ser a lo que ocurre en la vida real? y si fuera una razonable aproximación ¿a qué nos conduce?\nQuizás nos sugiera que lo más importante es mejorar la tasa base, \\({Pr(V)}\\), y eso requiere pensar mejor, no hacer muchas más pruebas o incluso ponerse exageradamente exigente."
  },
  {
    "objectID": "posts/concepto-y-modelos-experimentar/index.html#anova",
    "href": "posts/concepto-y-modelos-experimentar/index.html#anova",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "ANOVA",
    "text": "ANOVA\n\nConceptos básicos (modelo de una vía, un criterio, completamente aleatorizado)\nHay situaciones en las que la información que tenemos para predecir una respuesta la tenemos en forma cualitativa, incluso la presencia o ausencia de una categoría. Una variable categórica es una medición discreta y las clases no tienen ningún orden particular. Por ejemplo, consideremos de nuevo las diferentes especies en los datos de energía láctea. Algunas de ellas son simios, mientras que otras son monos del Nuevo Mundo. Podríamos preguntarnos cómo deberían variar las predicciones cuando la especie es un simio en lugar de un mono. El grupo taxonómico es una variable categórica, porque ninguna especie puede ser mitad simio y mitad mono (discreción), y no hay ningún sentido en el que uno sea más grande o más pequeño que el otro (desorden). Otros ejemplos comunes de variables categóricas son:\n\nSexo: macho, hembra\nEstado de desarrollo: lactante, juvenil, adulto\nRegión geográfica: África, Europa, Melanesia\n\nAlgunos de ustedes ya sabrán que variables como esta, llamadas rutinariamente factores, pueden ser fácilmente incluidas en los modelos lineales. Pero lo que no resulta tan intuitivo es la forma cómo se representan estas variables en un modelo. El ordenador hace todo el trabajo por nosotros, ocultando la maquinaria.\nLa hipótesis nula en un análisis de la varianza tipo I común es:\n\\[\nH_0: m_1 = m_2 = m_3 = ... = m_k\n\\]\n\n\n¿Cómo es que esta hipótesis se pone a prueba en un ANDEVA?\nPor cierto esta es una prueba “omnibus”, es decir ¡prueba todo (la igualdad de las medias) de un jalón!\nPara ver como es que opera el anova veamos el ejemplo que sigue. Considera un solo factor, “f”, con dos niveles.\n\n\nCódigo\nanova.data <- data.frame(y=c(rnorm(7, 5.4, 1), rnorm(7, 10.8, 1)))\nanova.data$f <- factor(rep(c(\"a\", \"b\"), each = 7))  \n\n\nPongamos estos datos en una gráfica simple, sgún el orden en el que fueron obtenidas las mediciones. Lo primero que haremos es definir la tabla de datos anova.data, como espacio de trabajo. Haremos esto con la función attach(). Esto hace que las variables contenidas en la tabla se puedan llamar directamente sin tener que anteponer el nombre de la estructura que las contiene. Esto es conveniente, pero si olvidamos regresar al espacio general de trabajo, con la función detach(), podemos encontrarnos con situaciones algo extrañas. En caso de que eso ocurra, resulta útil la función search(), que muestra los espacios de trabajo activos.\n\n\nCódigo\nattach(anova.data)\n\n\n\n\nCódigo\nplot(y)\nabline(mean(y), 0)\nfor (i in 1:length(y)) lines (c(i,i), c(mean(y), y[i]))\n\n\n\n\n\n\n\n¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\nCódigo\ndist_med_y <- sum((y - mean(y))**2)\ndist_med_y\n\n\n[1] 127.7306\n\n\nAhora incorporemos la información del factor f. Para esto hay que calcular los promedios de “y” que corresponden a los niveles de f\n\n\nCódigo\nmeans <- tapply(y, f, mean)\nmeans\n\n\n        a         b \n 4.981559 10.845612 \n\n\nGrafiquemos esta nueva estructura de datos.\n\n\nCódigo\nplot(y)\nlines(c(1, 7.5), c(means[1], means[1]))\nlines(c(7.5, 14), c(means[2], means[2]))\nfor (i in 1:7 ) lines (c(i,i), c(means[1], y[i]))\nfor (i in 8:14) lines (c(i,i), c(means[2], y[i]))\n\n\n\n\n\n\n\n¿Qué muestra esta gráfica? ¿a que equivale la suma de los trazos verticales?\n\n\nCódigo\ndist_med_s <- sum(m1=sum((y[1:7] - means[1])**2), \n                  m2=sum((y[8:14] - means[2])**2))\n\ndist_med_s\n\n\n[1] 7.3757\n\n\n\n\nSi las dos medias fueran iguales ¿cómo compararían estas dos gráficas?\n\n\n¿Qué interpretación tiene la diferencia entre las dos sumas mencionadas arriba?\nEsta diferencia se asocia con la siguiente gráfica:\n\n\nCódigo\nmodelo <- lm(y ~ f) # ¿qué estoy haciendo aquí?\nplot (y, col = \"red\")\nabline (mean(y), 0)\npoints(predict(modelo), pch = 16, col = \"lightblue\")\nfor (i in 1:14) lines(c(i, i), c(mean(y), predict(modelo)[i]), col = \"gray\")\n\n\n\n\n\nAhora la suma de estas líneas verticales es\n\n\nCódigo\ndist_med_s_y <- sum(sum((rep(means[1], 7) - mean(anova.data$y))**2),  \n                    sum((rep(means[2], 7) - mean(anova.data$y))**2))\ndist_med_s_y\n\n\n[1] 120.3549\n\n\nEstas tres formas de calcular las distancias entre datos y promedios se asocia con fuentes de variación\n\nvariaciones o error total\nvariaciones o error residual (componente aleatorio/efecto aleatorio)\nvariaciones o error del modelo (componente sistemático/efecto fijo)\n\nEn el cuadro de análisis de varianza se suele etiquetar a los componentes de error de acuerdo con su fuente. Se les acompaña con los grados de libertad, la suma de cuadrados de las distancias que mostré en las tres gráficas anteriores y luego los llamados cuadrados medios. Para referencia podemos pedrle a R que nos reporte el cuadro de ANOVA de este modelo.\n\n\nAnaliza la correspondencia entre los valores y las gráficas que vimos arriba con lo que reporta R.\n\n\nCódigo\nanova(modelo)\n\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nf          1 120.355 120.355  195.81 8.578e-09 ***\nResiduals 12   7.376   0.615                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\ndist_med_y\n\n\n[1] 127.7306\n\n\nCódigo\ndist_med_s\n\n\n[1] 7.3757\n\n\nCódigo\ndist_med_s_y \n\n\n[1] 120.3549\n\n\n\n\nCódigo\ndetach(anova.data)"
  },
  {
    "objectID": "posts/concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "href": "posts/concepto-y-modelos-experimentar/index.html#disposición-de-tratamientos-e-intereses-sobre-los-factores",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "Disposición de tratamientos e intereses sobre los factores",
    "text": "Disposición de tratamientos e intereses sobre los factores\n\nEfectos fijos\nQuizás la forma más simple de identificar las variables explicativas que tienen efectos fijos es pensar en ellas como variables cuyos niveles identifican en forma completa las condiciones de interés para el investigador. Por ejemplo, en el caso de un experimento que analiza el desempeño de larvas de mariposa que toman una dieta rica en proteinas y al mismo tiempo están expuestas a la presencia o no de un alcaloide. Estamos interesados precisamente en esas dietas y en la presencia o no del alcaloide. Estos dos factores son fijos. Es el tipo de variables que normalmente consideramos en nuestros objetivos de investigación. Se asume que su identificación y definición es completa, se asume que no hay más niveles de interés que los definidos y por lo tanto el modelo resultante no puede utilizarse para predecir fuera del ámbito de esas definiciones.\n\n\nEfectos aleatorios\nLas variables de efectos aleatorios surgen cuando se considera que el factor considerado no es sino una muestra de los posibles resultados que se pueden obtener de muestrear la condición que caracteriza el factor. Por ejemplo, si en un experimento para explorar la germinación de Bouteloua gracilis bajo distintas condiciones de temperatura en campo, se distribuyen las semillas en varios sitios de una zona de interés. Los aprecia que hay básicamente dos tipos de ambiente, suelos arenosos y suelos con algo de grava, así que se eligen 5 sitios en cada condición, y en cada uno de ellos se ponen a prueba dos tratamientos, “pisoteo por ganado” y “sin pisoteo por ganado”. Los 10 sitios elegidos estarían definidos como de efectos aleatorios, pues podemos ver que los niveles elegidos son en realidad una muestra de las posibles condiciones que prevalecen en la zona de estudio. Además, claramente el interés de la predicción es ser generalizable para toda la zona. A veces podemos pensar en esta forma de proceder como equivalente a un muestreo estratificado, en este caso, los tipos de ambiente son los estratos. No es el caso del tratamiento pisoteo. aprovechando podemos ver que en este experimento tendremos un mínimo de 4 combinaciones experimentales, y que ese arreglo mínimo se repetirá 5 veces, así que reqeriremos 20 unidades experimentales para realizar el estudio.\n\n\n¿Puedes darme un ejemplo en el que distingas entre efectos fijos y aleatorios?\n\n\nAnidamiento vs. cruzamiento\nLa anidación o el cruzamiento es otra característica de los datos, o más bien del diseño experimental. Hablamos de que un conjunto de variables están cruzadas en un diseño experimental cuando todos los posibles niveles de las variables están expuestas por igual entre ellas. Podríamos decir que las variables se combinan de “igual a igual”. Es decir, podemos tener tantas posibles combinaciones de las variables como el producto del numero de niveles que tengan. En el caso del experiment de Bouteloua, el experimento sugiere que los sitios y los tratamientos están “cruzados”, de ahí que tengamos necesidad de disponer por lo menos de 4 unidades experimentales.\nEl ejemplo de escuelas que ilustro a continuación debe ayudar a entender mejor estos conceptos. Si las clases son iguales para todas las escuelas, nos estaríamos refiriendo a algo así:\n\nEsto significa que cada clase se imparte por igual y en las mismas condiciones a cada escuela. Algo difícil de imaginar, ¡pero quizás no en los tiempos de la COVID-19!. Este es un diseño cruzado (algunos también podrían llamarlo afiliación múltiple). En R y con las funciones que ajustan modelos estadísticos lineales (lm() y glm()) se produce mediante el operador *.\nEl arreglo anidado se produce cuando las unidades experimentales están subordinadas a algún criterio de clasificación. Un factor B está anidado en otro factor A cuando cada nivel del factor B aparece asociado a un único nivel del factor A (los niveles de B están subordinados a los de A). Aquí tenemos clases anidadas en escuelas, lo cual es un escenario familiar.\n\nEl punto importante aquí es que, entre cada escuela, las clases tienen el mismo identificador, aunque sean distintas si están anidadas. La clase 1 aparece en la escuela 1, la escuela 2 y la escuela 3. Sin embargo, si los datos están anidados, la clase 1 en la escuela 1 no es la misma unidad de medida que la clase 1 en la escuela 2 y la escuela 3.\nNo es posible saber, simplemente inspeccionando los datos, si tenemos efectos aleatorios anidados o cruzados. Esto sólo puede determinarse con el conocimiento de los datos y el diseño experimental. Debido a esto, es muy importante especificar con suficiente claridad el diseño experimental incluyendo las operaciones involucradas para ponerlo en práctica, para poder construir correctamente el modelo estadístico correspondiente, ya que dependiendo de la naturaleza de las variables (fija o aleatoria), los modelos producirán resultados diferentes.\nEl concepto de variables aleatorias no es fácil de comprender, por lo que no hay que preocuparse demasiado por entenderlo completamente en este momento. También es útil tener en cuenta que el hecho de que una variable se considere fija o aleatoria en cierto grado dependerá de la interpretación de la persona que diseña el experimento y realiza el análisis. En R, la operación para incluir efectos anidados es el operador /.\nEn forma específica las interacciones derivadas de cruzamiento se pueden anotar en un modelo como a:b y un anidamiento a %in% b\nNaturalmente podemos encontrar situaciones en las que el experimento combina efectos aleatorios y fijos. Naturalmente, tal diseño se denomina de efectos mixtos."
  },
  {
    "objectID": "posts/concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "href": "posts/concepto-y-modelos-experimentar/index.html#la-tradición-de-prueba-de-hipótesis",
    "title": "Conceptos y Modelos en la experimentación",
    "section": "La tradición de prueba de hipótesis",
    "text": "La tradición de prueba de hipótesis\nEl planteamiento de la prueba de significancia estadística de hipótesis se pueden encontrar ya en el siglo XIX, su formalización teórica realmente ocurre en los años 20 y 30 del siglo XX con las publicaciones de Sir Ronald Fisher, Jerzy Neyman y Egon Pearson.\nEntre estos autores existieron diferencias filosóficas y conceptuales entre sus planteamientos y posturas. En special Fisher y Neyman sostuvieron acres debates que sólo se interrumpieron con el fallecimiento de Fisher en 1962. No obstante el debate continua hasta hoy.\nEl resultado es que el uso actual de la prueba estadística de hipótesis se ha conformado como un extraño híbrido surgido de una mezcla más o menos ecléctica de las dos formas de pensar y no tanto una teoría coherente sobre la prueba de hipótesis.\n\nEl procedimiento\nEl objetivo de una prueba de significancia es hacer inferencias sobre un parámetro que el investigador concibe asociado a un atributo numérico relevante de la población que define su objetivo de investigación. El procedimiento utiliza como base los datos de una muestra extraída de esa población. El enfoque se opera específicamente como un instrumento para excluir un valor o una gama de valores específicos como plausibles para el parámetro.\n\nEl paso a paso del formalismo de prueba de hipótesis\n\nConstruir un modelo estadístico. Se trata de un conjunto de supuestos sobre las variables de interés.\nEspecificar la hipótesis nula.\nDefinir un estadístico de contraste (frecuentemente llamada “la prueba estadística”).\nIdentificar la distribución del estadístico de contraste bajo los supuestos del modelo.\nCalcular, bajo el supuesto de la hipótesis nula, el valor del estadístico de contraste en la muestra observada.\nCalcular la probabilidad de tener un valor del estadístico como el resultante o un valor más extremo en la distribución de referencia (el famosos valor p).\nAceptar o rechazar la hipótesis nula. Si el valor p es menor que el criterio α de significancia (especificado a priori), se rechaza la hipótesis nula, en el caso contrario se acepta o por lo menos no se rechaza (por lo pronto).\n\nRechazar la hipótesis nula es algo que quizás produce poca tensión emocional, quizás hasta un alivio, finalmente, el investigador sospecha (desea mostrar) que lo interesante está en otra parte, en su juego de hipótesis alternativas.\n\n\n\n¿Es este procedimiento afín al refutacionismo Popperiano?.\nPara interpretar correctamente un valor p se necesita tener claro que se opera dentro de una marco conceptual frecuentista. Esto lleva a que se conciba a los parámetros del modelo estadístico como constantes en la población objetivo (valor fijo que nunca se conoce en realidad).\nAdemás se asume que, al menos conceptualmente, sería posible repetir el experimento un número infinito de veces. También se asume que siempre se está muestreando la misma población objetivo (universo muestral) así que los parámetros tienen el mismo valor, pero las muestras fluctúan aleatoriamente.\nBajo estos supuestos es aceptable considerar que el estadístico de prueba se distribuye de acuerdo con el modelo de probabilidades propuesto para construir el contraste y por lo tanto da cuenta de las variaciones esperadas entre las diferentes repeticiones del experimento.\nEn la aproximación tradicional a la contrastación estadística de hipótesis (frecuentista) se parte de la formulación de proposiciones hipotéticas que son descritas con referencia a alguna distribución de probabilidades.\nEn este marco conceptual, un componente es la llamada hipótesis nula (\\(H_{0}\\)). Se concibe como un planteamiento que asume la ausencia de efecto de los “factores explicativos”.\nEn contraste se propone una o más hipótesis alternativas (\\(H_{1...n}\\)), en las que se valora algún o algunos efectos de los “factores explicativos”. La proposición hipotética que hacemos se traduce en valores que podemos comparar con un conjunto de valores a los que consideramos observados. La diferencia entre estos dos conjuntos de valores nos permiten valorar la factibilidad de nuestra proposición.\n\nEn la práctica, suele ocurrir que se concentre la atención en la hipótesis nula expresada con la gran simplicidad que implica la ausencia de efectos y se proceda con menor rigurosidad el análisis de la hipótesis alternativa, la que suele procesarse en forma más bien exploratoria mediante procedimientos de comparaciones múltiples.\n\n\nCríticas\nEntre las críticas que se han hecho al procedimiento clásico de prueba de hipótesis está la que señala que el valor p, al excluir el valor de cero como valor plausible para el parámetro, no aporta información completa sobre los valores que sí son plausibles. Esto implica que la significancia estadística no implica relevancia práctica.\n\n\n¿Cómo interpretas esta afirmación?\nEn el mismo razonamiento, un “valor de p extremadamente significativo” no hace otra cosa que excluir el cero como valor plausible para el parámetro no precisamente sobre la calidad del hallazgo.\nOtra crítica señala que interpretar el valor p en términos de evidencia en contra de la hipótesis nula (siguiendo el pensamiento de Fisher) o la plausibilidad de que la hipótesis nula sea falsa a veces se expresan equivocadamente como la probabilidad de que la hipótesis nula sea falsa en consideración de la evidencia (E) disponible. Al plantearlo así, formalmente se enuncia como \\(P(H_{0}|E)\\). Pero esto no es apropiado, formalmente resulta ser una inconsistencia en la lógica del planteamiento.\n\n\n¿Puedes reconocer esta inconsistencia?\nLa inconsistencia está en que, en primer lugar como dije arriba, el valor p se define dentro del marco frecuentista y se concibe que los parámetros son valores constantes, aunque desconocidos (¡supuesto estadístico de efectos fijos!). No se trata de los parámetros de alguna distribución de probabilidades (observada o no). Por tanto, no tiene sentido asignar probabilidades a los distintos valores estimados del parámetro.\nAdemás, el valor p se calcula bajo el supuesto de que la hipótesis nula es cierta; esto hace imposible, por construcción, interpretarlo como la probabilidad de que la hipótesis alternativa sea cierta. La probabilidad a la que se refiere el valor p guarda más relación con la probabilidad inversa, \\(P(E|H{0})\\). ¿Qué tan probable sería tener una muestra como la que tenemos enfrente, si la hipótesis considerada fuera cierta?. Esto se conoce como la verosimilitud, es decir, la probabilidad de observar los datos que se han obtenido en un estudio suponiendo que los atributos del modelo fueran ciertos. La verosimilitud valora a la muestra como un resultado condicional a los supuestos hechos en el modelo estadístico y en este caso, la hipótesis nula.\nSin embargo, la probabilidad que realmente interesa -por ejemplo, al investigador de nuestro ejemplo- es la anteriormente mencionada \\(P(H_{0}|E)\\). Aunque no está definida dentro del marco frecuentista, en el marco Bayesiano sí se define. Las probabilidades \\(P(E|H_{0})\\) y \\(P(H_{0}|E)\\) no son iguales.\n\n\n¿Recuerdas qué representa cada uno de ellas? ¿cuál es la relación entre ambas?\nOtra crítica interesante surge de la llamada paradoja de Lindley (1957), quien mostró, con una formulación Bayesiana, que existe la posibilidad de tener datos congruentes con rechazar una hipótesis nula con un bajo valor p y que al mismo tiempo llevan a una probabilidad posterior alta.\nEncontró que es perfectamente posible, a partir de los mismos datos E, obtener al mismo tiempo una \\(P(E|H_{0})\\) = 0.05 (baja probabilidad de obtener una muestra como la que se observó, si \\(H_{0}\\) fuera cierta) y \\(P(H_{0}|E)\\) = 0.95 (fuerte evidencia en favor de \\(H_{0}\\)). Este resultado contradictorio permite ver lo cuestionable que resulta interpretar el valor p como evidencia en contra de la hipótesis nula.\nSe ha contrargumentado que la paradoja requiere muestras grandes para manifestarse, y se oponen a los supuestos adicionales que requiere el análisis Bayesiano. Se ha defendido que bajo condiciones razonables, un bajo valor p generalmente implica una baja probabilidad posterior, es decir, poca evidencia para la hipótesis nula. Sin embargo, a pesar de esta defensa al enfoque clásico, se ha encontrado que los valores p sistemáticamente sobrestiman la evidencia en contra de la hipótesis nula.\nEn resumen, el valor mismo de p, resultado de una prueba clásica de hipótesis, no aporta mucha información de interés para los investigadores. En caso de optar por la hipótesis alternativa con base en la p, no se favorece llegar a ninguna conclusión sustancial sobre posibles explicaciones alternativas, lo único que queda claro es que la nula probablemente es falsa.\nPara que quede claro, hay que insistir en que si el valor p es juzgado significativo, únicamente nos inclina a excluir un solo valor como estimador plausible para el parámetro. Peor aún, el significado de plausible en la última expresión tiene una relación nebulosa con la probabilidad que sí le interesa a los investigadores: la probabilidad posterior de que la hipótesis nula sea cierta a la luz de la evidencia recopilada \\(P(H_{0}|E)\\).\n\n\n¿Qué piensas de la paradoja de Lindley y sus implicaciones\n\n\nRemedios y alternativas para la prueba estadística de la hipótesis nula\nPara enfrentar algunos de los inconvenientes del enfoque clásico de prueba de hipótesis se ha recomendado ahora sustituir el valor p por un intervalo de confianza que abarca un conjunto de valores que permiten valorar si es razonable rechazar la hipótesis nula y además, en caso contrario proporciona una gama de valores que caracterizan al parámetro, lo que resulta de mucho interés.\nLa práctica de presentar intervalos de confianza, posiblemente en conjunto con p, constituye una respuesta a la crítica de que sólo se excluye un valor como valor plausible para el parámetro. Además, hacer esto proporciona información sobre significancia. Si el intervalo no incluye el valor de cero, entonces se declararía el resultado como estadísticamente significativo. El intervalo informa también sobre el posible tamaño del efecto.\nA la luz de las críticas, Muchos autores ven necesario actualmente adoptar el marco Bayesiano para enfrentar las deficiencias del enfoque clásico.\n\n\nPotencia de la prueba\nEn la práctica, la potencia de la prueba depende del grado de dispersión en los datos. Si se está asumiendo un modelo de probabilidades Gaussiano (distribución normal), el factor de disperción o escala se relaciona con la varianza. Por lo tanto, es usual notar que el mismo cálculo del error estandar, \\(s_{e}=\\frac{\\sigma}{\\sqrt{n}}\\), sugiere la solución.\n\n\nSe puede incrementar el tamaño de muestra, n,\n\n\n\n¿Por qué funcionaría esto?\n\nAumentar la precisión con la que se estima \\(\\sigma^2\\),\n\n\n\n¿Cómo se puede hacer esto?\nEs interesante apreciar, que la búsqueda de un tamaño de muestra apropiado para un estudio que estemos planeando, se puede lograr muy eficazmente haciendo simulaciones como las que hemos estado viendo en este bloque del curso. A través de este camino y haciendo el esfuerzo de especificar hipótesis alternativas relevantes se pueden resolver preguntas como:\n\n¿Cuál es el tamaño de muestra necesario para detectar una cierta diferencia en lo que medimos?\n¿Cuál es la diferencia detectable dada una n o una potencia de la prueba (\\(1-\\beta\\))?\n¿Cuál es la potencia (\\(1-\\beta\\)) dado un n y cierta diferencia con \\(H_{a}\\) de interés?"
  },
  {
    "objectID": "posts/diagramas-causales/index.html",
    "href": "posts/diagramas-causales/index.html",
    "title": "Diagramas Causales",
    "section": "",
    "text": "Judea Pearl se ha aproximado a la causalidad desde una peerspectiva matemática y computacional. En ese camino retomó y dio un nuevo impulso a los llamados modelos probabilísticos gráficos en su variante de redes Bayesianas. También ha incursionado en los llamados modelos de ecuaciones estructuradas, también de la familia de los modelos gráficos. Todo ello vinculado con los Gráfos Acíclicos Dirigidos, a los que llamaremos DAG (del inglés directed acyclic graphs). Pearl y colaboradores así como otros investigadores ahora, han venido desarrollando la teoría que nos permite analizar tales DAGs para comprender los patrones de dependencia causal así como los de correlación que implica una proposición causal dada. En esta contribución buscamos mostrarles algunos elementos interesantes de esto y con ello, animarlos a estudiar estas ideas con mayor profundidad."
  },
  {
    "objectID": "posts/diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "href": "posts/diagramas-causales/index.html#ejemplo-efectos-de-sesgo-en-las-causas",
    "title": "Diagramas Causales",
    "section": "Ejemplo: Efectos de sesgo en las causas",
    "text": "Ejemplo: Efectos de sesgo en las causas\nEl primer ejemplo de simulación que haremos parte de la proposición causal:\n\nEl aprendizaje (X) tiene como efecto el conocimiento (C), y conocer provoca la comprensión (Y),\n\nAdemás actúan algunos factores exógenos (U, son el término de error en el modelo estadístico). En la vida real, el aprendizaje, el conocimiento y la comprensión pueden ser operacionalizados por algún cuestionario y estandarizados para dar la precisión necesaria al análisis.\nEl ejemplo consiste ahora en producir un conjunto de datos que cumpla, por diseño, con la descripción que acabo de hacer. En este caso utilizaremos las ecuaciones siguientes.\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\nen donde N(μ, σ) indica que existen variaciones por causas no observadas que vamos a suponer generan oscilaciones aleatorias o un ruido, cuya distribución es semejante a la que produciría una distribución Normal de probabilidades. Ahora escribimos estas ecuaciones en un escript de R.\n\n\nCódigo\nset.seed(1896) # Si interesa repetir la misma secuencia de numeros aleatorios. Habilita Repetibilidad\nn <- 1000 # Sample Size\n\naprender <- rnorm(n)\nconocer <- 5 * aprender + rnorm(n)  # Conocer depende del comportamiento de aprender\nentender <- 3 * conocer + rnorm(n)  # entender depende del comportamiento de conocer\n\n# Para comodidad de cálculo junto los datos en una tabla, un \"data.frame\"\ndatos <- data.frame(aprender, conocer, entender)\n\n\nEl DAG que describe la situación descrita lo podemos producir en R con ayuda de la biblioteca DAGitty. Con las instrucciones siguentes.\n\n\nCódigo\nlibrary(dagitty)\n\nejemplo_1_DAG <- dagitty('dag{\n                     aprender -> conocer\n                     conocer -> entender\n\n                     aprender[exposure, pos=\"0,0\"]\n                     conocer[pos=\"1,0\"]\n                     entender[outcome, pos=\"2,0\"]}')\noptions(repr.plot.width=10, repr.plot.height=3)\npar(cex=2, lwd = 5)\nplot(ejemplo_1_DAG)\n\n\n\n\n\nSi optamos por no “corregir” la estimación por el efecto del mediador, Supondríamos que el efecto total del aprendizaje sobre el entendimiento no tiene sesgo. La estimación de esta relación la obtenemos con el modelo que calculamos en ejemplo_1_ecuación_1.\n\n\nCódigo\nejemplo_1_ecuacion_1 <- lm(entender ~ aprender)\nsummary(ejemplo_1_ecuacion_1)$coefficients[,1:2]\n\n\n               Estimate Std. Error\n(Intercept) -0.02227676 0.09661146\naprender    15.12087585 0.09781602\n\n\n¿Qué piensas de este resultado? ¿El modelo es congruente con la proposición causal? Si ahora optamos por sí “corregir” los efectos considerando que el conocimiento puede estar interfiriendo la estimación del efecto total del aprendizaje sobre el entendimiento. Ahora, el modelo que da cuenta de esta nueva situación es el que calculamos en ejemplo_1_ecuación_2.\n\n\nCódigo\nejemplo_1_ecuacion_2 <- lm(entender ~ aprender + conocer)\nsummary(ejemplo_1_ecuacion_2)$coefficients[,1:2]\n\n\n                Estimate Std. Error\n(Intercept) -0.004947807 0.03077153\naprender     0.121514701 0.16253665\nconocer      2.981736249 0.03171170\n\n\nLos resultados de esta exploración produce dos ecuaciones:\n\\[\n\\begin{align}\nX &= U_{X}, \\, U_{X} \\sim N(0, 1) \\\\\nC &= 5 X + U_{C}, \\, U_{C} \\sim N(0, 1) \\\\\nY &= 3 C + U_{Y}, \\, U_{Y} \\sim N(0, 1)\n\\end{align}\n\\]\n\\[\n\\begin{align}\nentender &= -0.022 + 15.12 \\, aprender  + \\varepsilon \\\\\nentender &= -0.005 +  0.122 \\, aprender + 2.98 \\, conocer + \\varepsilon\n\\end{align}\n\\]\n\n¿Puedes explicar qué pasó aquí?\n¿Qué relación tiene esto con lo que cabría esperar de acuerdo con as reglas de la “separación direccional”?\n¿Qué sugieren los datos del ajuste del modelo estadístico lm?\n¿Tienen relevancia el aprendizaje y el conocimiento?\n¿Cuál es el modelo adecuado dada la proposición causal considerada?\n\nPodemos utilizar a dagitty para explorar el DAG directamente de la siguiente manera. Podemos preguntarnos cuales serían las formas de separar el grafo con criterios de independencia condicional. Se trata de aplicar las tres reglas de separación direccional al grafo. Afortunadamente dagitty lo puede hacer por nosotros.\n\n\nCódigo\nimpliedConditionalIndependencies(ejemplo_1_DAG)\n\n\naprn _||_ entn | cncr\n\n\n¿Qué indica este resultado?\n\\[\naprender \\,\\, \\ci \\,\\, entender \\,\\, | \\,\\, conocer\n\\]\nAdemás de hacer esto por nosotros, la biblioteca dagitty nos permite poner a prueba la correspondencia de los datos con estas ideas. Lo hacemos con la función localTests.\nLa función localTests calcula el coeficiente de correlación de Pearson para cada condición considerada. El resultado incluye el valor p y el intervalo de confianza del coeficiente de correlación para cada una de las relaciones de independencias condicionales implicadas por la estructura del modelo.\nEl coeficiente de correlación de Pearson varía entre -1 y 1. El valor 0 implica que no hay correlación, mientras que -1 o 1 implica una correlación lineal perfecta.\nEl valor p de la prueba indica la probabilidad de obtener un conjunto de datos como el que se tiene, asumiendo la hipótesis de que la condición de independencia correspondiente es verdadera.\nPor lo tanto, un coeficiente de correlación cercano a 0 con un valor p alto es sugerente de que la independencia condicional indicada es congruente con el patrón detectable en los datos.\nPor el contrario, un valor alto del coeficiente de correlación con un valor p bajo sugiere que la independencia condicional considerada no es congruente con el conjunto de datos.\nLas columnas etiquetadas com 2.5% y 97,5% contienen el intervalo de confianza del 95% para el coeficiente de correlación.\nCuanto más estrecho sea el intervalo de confianza y alejado de cero resulte, más fuerte será la evidencia de que la independencia condicional que implica el DAG no se mantiene en el conjunto de datos disponible para el ensayo.\n\n\nCódigo\n# El tipo de análisis \"cis\" usa regresión lineal para poner a prueba la correlación\nejemplo_1_analisis_DAG <- localTests(x=ejemplo_1_DAG, data=datos, type=\"cis\") \n\nprint(ejemplo_1_analisis_DAG)\n\n\n                        estimate   p.value        2.5%      97.5%\naprn _||_ entn | cncr 0.02367054 0.4549614 -0.03840997 0.08556934\n\n\nSi lo preferimos, podemos obtener una representación gráfica de estos resultados.\n\n\nCódigo\noptions(repr.plot.width=14, repr.plot.height=5)\npar(cex=1.5, lwd = 3, oma = c(1,2,1,1), mar = (c(4,2,1,1) + 0.5))\nplotLocalTestResults(ejemplo_1_analisis_DAG, col = \"blue\")\n\n\n\n\n\n\n¿Puedes comentar tu interpretación de estos resultados del modelo y los datos sobre aprendizaje y conocimiento?"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes-glex1",
    "href": "posts/dis-comp-aleat/index.html#respuesta-de-cultivares-a-fertilizantes-glex1",
    "title": "Experimentos completamente aleatorizados",
    "section": "Respuesta de Cultivares a fertilizantes (GLEX1)",
    "text": "Respuesta de Cultivares a fertilizantes (GLEX1)\nEjemplo tomado de Crawley (1998). Glim for Ecologists. Oxford. UK.\nEs un experimento en el que se midió el crecimiento (masa seca al cosechar = y) de plantas tratadas con 10 concentraciones diferentes de suplemento mineral como fertilizante, f. El experimento fue realizado con dos cultivares diferentes, g. Uno fue clonado de plantas de un ambiente árido y el otro de uno húmedo. Todas las plantas de cada tipo, sin restricciones, fueron asignadas aleatoriamente a los distintos niveles de fertilizante.\n\nLectura de datos\n\n\nCódigo\nGLEX1 <- read.table(\"GLEX1.DAT\",\n                    col.names=c(\"fertilizante\", \"rendimiento_peso\")) \n\nhead(GLEX1)\n\n\n  fertilizante rendimiento_peso\n1            1           2.8215\n2            2           2.3590\n3            3           3.0912\n4            4           2.5297\n5            5           3.4753\n6            6           3.6493\n\n\nA veces hay archivos que contienen datos faltantes o perdidos. Podemos enfrentar eso con la función complete.cases() que revisa linea por linea el archivo y regresa “verdadero” si todas las columnas tienen datos válidos y “falso” si hay huecos. Esta lista de “verdaderos” y “falsos” la podemos usar para elegir que filas del archivo de datos están completas y así podemos eliminarlas del conjunto de datos que vamos a procesar.\nSobre los datos limpios, generamos la variable indicativa del tipo de ambiente del que se tomo la planta que se clonó.\n\n\nCódigo\n# En caso de que haya datos extra, elimino registros leidos como datos erróneos\nGLEX1 <- GLEX1[complete.cases(GLEX1), ]\n\n\n\n\nGenera los factores genotipo y fertilizante\n\n\nCódigo\nGLEX1$cultivar <- factor(rep(c(\"seco\",\"humedo\"), each=10))\nGLEX1$fertilizante <- factor(GLEX1$fertilizante) \n\nhead(GLEX1)\n\n\n  fertilizante rendimiento_peso cultivar\n1            1           2.8215     seco\n2            2           2.3590     seco\n3            3           3.0912     seco\n4            4           2.5297     seco\n5            5           3.4753     seco\n6            6           3.6493     seco\n\n\n\n\ngráfica de masa seca contra fertilizante mineral - sin diferenciar tratamientos\nVeamos los datos en una gráfica simple. La función plot hace cosas distintas según el tipo de datos que le demos. Para generar la gráfica simple que queremos aquí, conviene que los valores de fertilizante sean interpretados como valores numéricos. Esto lo logramos con la funnción as.numeric\n\n\nCódigo\nplot(as.numeric(GLEX1$fertilizante), GLEX1$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"p\")\n\n\n\n\n\nPara explorar mejor los datos podemos marcar en la gráfica las obsevaciones que pertenecen a cada condición. En este caso, te propongo poner el nombre que le dimos al “tratamiento”.\nGráfica de masa seca contra fertilizante mineral diferenciando por genotipos\n\n\nCódigo\nplot(as.numeric(GLEX1$fertilizante), \n     GLEX1$rendimiento_peso, xlab=\"fertilizante\", ylab=\"biomasa\", type=\"n\")\ntext (GLEX1$fertilizante, GLEX1$rendimiento_peso, labels=GLEX1$cultivar)\n\n\n\n\n\nPodemos ver las características estadísticas de lo que pasa con la biomasa que produce cada genotipo\n\n\nResumen de los datos de masa por genotipo\n\n\nCódigo\nby (GLEX1, GLEX1$cultivar, summary)\n\n\nGLEX1$cultivar: humedo\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 4.405   humedo:10  \n 2      :1     1st Qu.: 5.617   seco  : 0  \n 3      :1     Median : 8.592              \n 4      :1     Mean   : 8.716              \n 5      :1     3rd Qu.:10.977              \n 6      :1     Max.   :14.502              \n (Other):4                                 \n------------------------------------------------------------ \nGLEX1$cultivar: seco\n  fertilizante rendimiento_peso   cultivar \n 1      :1     Min.   : 2.359   humedo: 0  \n 2      :1     1st Qu.: 2.889   seco  :10  \n 3      :1     Median : 3.562              \n 4      :1     Mean   : 4.866              \n 5      :1     3rd Qu.: 6.355              \n 6      :1     Max.   :10.130              \n (Other):4                                 \n\n\nAhora podemos realizar el análisis estadístico mediante modelos. Hagamos un análisis con el enfoque “tradicional” en R. Lo primero que haremos es configurar el entorno de análisis, esto significa elegir el tipo de contrastes que queremos operar al ajustar modelos reparametrizados. Haremos esto con opción contrasts en la función options(contrasts=...)\nPara asegurarnos de que los estimadores del modelo toman el primer nivel como referencia hay que usar el modo de reparametrización “treatment”. Hay otras formas de reparametrización, como podrás ver en la ayuda de contr.treatment.\n\n\nCódigo\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n\n\n\n\najusta modelo nulo - sólo la media\n\n\nCódigo\naj1 <- lm (rendimiento_peso ~ 1, data = GLEX1)\nsummary(aj1)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ 1, data = GLEX1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.432 -3.185 -1.006  2.555  7.711 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   6.7912     0.8067   8.419 7.79e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.608 on 19 degrees of freedom\n\n\n\n\nCódigo\n# Agregamos el efecto del fertilizante\naj2 <- update(aj1, .~ . + fertilizante)\nanova(aj2)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df Sum Sq Mean Sq F value Pr(>F)\nfertilizante  9 142.75  15.861  1.5174 0.2622\nResiduals    10 104.53  10.453               \n\n\nNótese que el número de niveles de fertilizante es 10, así que los grados de libertad son 10-1=9. De modo semejante el número de observaciones es 20, así que los grados de libertad del residuo descuenta los grados de libertad del fertilizante y 1 (por la estimación de la media general): 20 - 9 - 1 = 10\n\n\nCódigo\n# agregamos el cultivar\naj3 <- update(aj2,  .~ . + cultivar)\nanova(aj3)\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n             Df  Sum Sq Mean Sq F value   Pr(>F)   \nfertilizante  9 142.747  15.861  4.6953 0.015392 * \ncultivar      1  74.125  74.125 21.9434 0.001145 **\nResiduals     9  30.402   3.378                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPodemos intentar hacer un modelo completo, es decir con todos los posibles factores y combinaciones que pueden producirse. Sin embargo este modelo consume todos los grados de liberta (observacione) con que contamos pues cada tratamiento fue ensayado una sola vez en este experimento. De todos modos lo podemos intentar para ver que nos dice R.\n\n\nCódigo\n# agregamos una pendiente diferente para cada genotipo\naj4 <- update(aj3,  .~ . + cultivar:fertilizante)\nanova(aj4)\n\n\nWarning in anova.lm(aj4): ANOVA F-tests on an essentially perfect fit are\nunreliable\n\n\nAnalysis of Variance Table\n\nResponse: rendimiento_peso\n                      Df  Sum Sq Mean Sq F value Pr(>F)\nfertilizante           9 142.747  15.861     NaN    NaN\ncultivar               1  74.125  74.125     NaN    NaN\nfertilizante:cultivar  9  30.402   3.378     NaN    NaN\nResiduals              0   0.000     NaN               \n\n\nLa scuencia de ajustes produce estos cambios en devianza\n\n\nCódigo\nanova(aj1, aj2, aj3)\n\n\nAnalysis of Variance Table\n\nModel 1: rendimiento_peso ~ 1\nModel 2: rendimiento_peso ~ fertilizante\nModel 3: rendimiento_peso ~ fertilizante + cultivar\n  Res.Df     RSS Df Sum of Sq       F   Pr(>F)   \n1     19 247.274                                 \n2     10 104.527  9   142.747  4.6953 0.015392 * \n3      9  30.402  1    74.125 21.9434 0.001145 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nModelo mínimo adecuado\nestos resultados sugieren que el modelo 3 es mínimo adecuado resumen del modelo mínimo adecuado\n\n\nCódigo\nsummary(aj3)\n\n\n\nCall:\nlm(formula = rendimiento_peso ~ fertilizante + cultivar, data = GLEX1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6653 -0.7855  0.0000  0.7855  2.6653 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)   \n(Intercept)      5.9538     1.3630   4.368  0.00180 **\nfertilizante2   -0.1251     1.8379  -0.068  0.94720   \nfertilizante3    0.5784     1.8379   0.315  0.76014   \nfertilizante4   -0.5614     1.8379  -0.305  0.76695   \nfertilizante5    3.1205     1.8379   1.698  0.12376   \nfertilizante6    2.3383     1.8379   1.272  0.23518   \nfertilizante7    3.3713     1.8379   1.834  0.09981 . \nfertilizante8    5.7776     1.8379   3.144  0.01186 * \nfertilizante9    5.8829     1.8379   3.201  0.01082 * \nfertilizante10   7.2434     1.8379   3.941  0.00340 **\ncultivarseco    -3.8503     0.8219  -4.684  0.00115 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.838 on 9 degrees of freedom\nMultiple R-squared:  0.8771,    Adjusted R-squared:  0.7404 \nF-statistic:  6.42 on 10 and 9 DF,  p-value: 0.004992\n\n\nComo un ejercicio haz el cálculo de los valores de y, a parir de los valores estimados por el modelo. Lo puedes hacer a mano, con ayuda de una calculadora del super, en Excel o equivalente, o quizás con ayuda de R mismo. En este último caso te doy como pista la función coef, con la que tendrás acceso a los coeficientes del modelo.\n¿Podrías escribir un programa/función en R para calcular los valores esperados?\nPara comprender con exactitud que es lo que hace exactamente R al ajustar un modelo de regresión o ANDEVA, como este podemos usar la función model.matrix() aplicada al modelo que nos interese analizar. En este caso lo ejemplificaré con el modelo mínimo adecuado aj3. Así podemos ver en acción el uso de las formas de reparametrización\n\n\nCódigo\nmodel.matrix(aj3)\n\n\n   (Intercept) fertilizante2 fertilizante3 fertilizante4 fertilizante5\n1            1             0             0             0             0\n2            1             1             0             0             0\n3            1             0             1             0             0\n4            1             0             0             1             0\n5            1             0             0             0             1\n6            1             0             0             0             0\n7            1             0             0             0             0\n8            1             0             0             0             0\n9            1             0             0             0             0\n10           1             0             0             0             0\n11           1             0             0             0             0\n12           1             1             0             0             0\n13           1             0             1             0             0\n14           1             0             0             1             0\n15           1             0             0             0             1\n16           1             0             0             0             0\n17           1             0             0             0             0\n18           1             0             0             0             0\n19           1             0             0             0             0\n20           1             0             0             0             0\n   fertilizante6 fertilizante7 fertilizante8 fertilizante9 fertilizante10\n1              0             0             0             0              0\n2              0             0             0             0              0\n3              0             0             0             0              0\n4              0             0             0             0              0\n5              0             0             0             0              0\n6              1             0             0             0              0\n7              0             1             0             0              0\n8              0             0             1             0              0\n9              0             0             0             1              0\n10             0             0             0             0              1\n11             0             0             0             0              0\n12             0             0             0             0              0\n13             0             0             0             0              0\n14             0             0             0             0              0\n15             0             0             0             0              0\n16             1             0             0             0              0\n17             0             1             0             0              0\n18             0             0             1             0              0\n19             0             0             0             1              0\n20             0             0             0             0              1\n   cultivarseco\n1             1\n2             1\n3             1\n4             1\n5             1\n6             1\n7             1\n8             1\n9             1\n10            1\n11            0\n12            0\n13            0\n14            0\n15            0\n16            0\n17            0\n18            0\n19            0\n20            0\nattr(,\"assign\")\n [1] 0 1 1 1 1 1 1 1 1 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$fertilizante\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$cultivar\n[1] \"contr.treatment\"\n\n\n\n\nIntervalos de confianza\nComo hemos visto. La valoración del modelos mínimo adecuado es una declaración de una posible hipótesis alternativa, la más cercana a la muestra que, en esta ocasión obtuvimos. Sin embargo, no hay garantía de ningún tipo de que en otra oportunidad los estimadores serán los mismos. Esto es un recordatorio de que la famosa p nos es en lo que debemos centrar nuestras esperanzas. El asunto es la reflexión sobre las hipótesis alternativas, es decir, las que realmente interesan al investigador y ojalá haga los más explícitas posibles. Una manera de ver el ámbito de estados alternativos del sistema la tenemos cuando visualizamos los intervalos de confianza que nuestro modelo mínimo adecuado produce. En el sitio RPub pueden encontrar ayuda para utilizar R en el análisis de sus datos, aquí encontraran un texto sobre intervalos de confianza. No deja de ser un ejercicio exploratorio y algo subjetivo, pero también potencialmente productivo para acercarnos a comprender mejor el comportamiento del sistema de nuestro interés.\nUn primer conjunto de intervalos de confianza son los asociados con los parámetros del modelo, es decir, la gama de valores de los coeficientes de regresión que podríamos esperar tener en el ajuste del modelo. A continuación les muestro como podemos obtener, con la función confint estos intervalos en R.\n¿Como interpretas estos valores\n\n\nCódigo\nconfint(aj3, level = 0.95)\n\n\n                    2.5 %    97.5 %\n(Intercept)     2.8703275  9.037193\nfertilizante2  -4.2828496  4.032550\nfertilizante3  -3.5792496  4.736150\nfertilizante4  -4.7191496  3.596250\nfertilizante5  -1.0371496  7.278250\nfertilizante6  -1.8194496  6.495950\nfertilizante7  -0.7863496  7.529050\nfertilizante8   1.6199004  9.935300\nfertilizante9   1.7252004 10.040600\nfertilizante10  3.0857004 11.401100\ncultivarseco   -5.7096998 -1.990940\n\n\nOtro intervalo de confianza de interés es el que podemos asociar con lo que puede predecir el modelo. En R este intervalo de confianza lo podemos obtener así:\n\n\nCódigo\npredict(aj3, interval = \"confidence\", level = 0.95)\n\n\n        fit        lwr       upr\n1   2.10344 -0.9799925  5.186873\n2   1.97829 -1.1051425  5.061723\n3   2.68189 -0.4015425  5.765323\n4   1.54199 -1.5414425  4.625423\n5   5.22399  2.1405575  8.307423\n6   4.44169  1.3582575  7.525123\n7   5.47479  2.3913575  8.558223\n8   7.88104  4.7976075 10.964473\n9   7.98634  4.9029075 11.069773\n10  9.34684  6.2634075 12.430273\n11  5.95376  2.8703275  9.037193\n12  5.82861  2.7451775  8.912043\n13  6.53221  3.4487775  9.615643\n14  5.39231  2.3088775  8.475743\n15  9.07431  5.9908775 12.157743\n16  8.29201  5.2085775 11.375443\n17  9.32511  6.2416775 12.408543\n18 11.73136  8.6479275 14.814793\n19 11.83666  8.7532275 14.920093\n20 13.19716 10.1137275 16.280593\n\n\n¿Qué muestran estos valores?\n¿Qé se te ocurre para utilizar en tu reporte de resultados este tipo de intervalos de confianza?\n\n\ncrítica al modelo y recursos diagnósticos\n\n\nCódigo\nplot(aj3)"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#lectura-ded-datos",
    "href": "posts/dis-comp-aleat/index.html#lectura-ded-datos",
    "title": "Experimentos completamente aleatorizados",
    "section": "Lectura ded datos",
    "text": "Lectura ded datos\n\n\nCódigo\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nGLEX11 <- read_excel(\"GLEX11.xlsx\",\n    col_types = c(\"numeric\", \"numeric\", \"numeric\"),\n    col_names = TRUE)"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#definición-de-los-factores",
    "href": "posts/dis-comp-aleat/index.html#definición-de-los-factores",
    "title": "Experimentos completamente aleatorizados",
    "section": "Definición de los factores",
    "text": "Definición de los factores\nLos datos contienen información cualitativa, así que necesitamos definir esas piezas de información como factores. Aprovecharemos para experimentar con los factores de tipo “ordenado”. Esta variante de factor aprovecha el contenido seminumérico que pudiéramos tener en alguna variable. En este caso lo haremos así para el contenido de proteína.\n\n\nCódigo\n# Uso la función \"ordered\" que genera factores ordenados, \n# útil para aprovechar datos \"semicuantitativos\" y probar polinomios\n\n# Enfoque antiguo con data.frame\n#GLEX11$proteina <- ordered(GLEX11$proteina, c(1,2,3), \n#                           c(\"bajo\", \"medio\", \"alto\"))\n#\n#GLEX11$alcaloide <-factor(GLEX11$alcaloide, c(1,2), c(\"ausente\", \"presente\"))\n#\n\n# Enfoque actual con tibble\nGLEX11 <- GLEX11 %>% mutate(proteina = ordered(proteina, c(1,2,3), \n                                     c(\"bajo\", \"medio\", \"alto\")),\n                  alcaloide = factor(alcaloide, c(1,2), \n                                      c(\"ausente\", \"presente\")))"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#exploración-de-medias",
    "href": "posts/dis-comp-aleat/index.html#exploración-de-medias",
    "title": "Experimentos completamente aleatorizados",
    "section": "exploración de medias",
    "text": "exploración de medias\nSiempre es conveniente hacer una revisión previa de los datos y considerar los patrones que apreciamos en ellos como fuente de ideas o simplemente para verificar que no haya errores de algún tipo.\n\n\nCódigo\n#\n# Enfoque antiguo con data.frame\n# Para simplificar el acceso a los datos uso la función attach\n#attach(GLEX11)\n#aggregate(list(talla=talla), list(proteina=proteina), mean)\n#aggregate(list(talla=talla), list(alcaloide=alcaloide),mean)\n#tapply(talla, list(proteina, alcaloide), mean)\n\n# Con un tibble es más práctico hacer esto\nGLEX11 %>% group_by(proteina) %>%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina promedio\n  <ord>       <dbl>\n1 bajo         5.5 \n2 medio        5.25\n3 alto         4.25\n\n\nCódigo\nGLEX11 %>% group_by(alcaloide) %>%\n           summarize(promedio = mean(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide promedio\n  <fct>        <dbl>\n1 ausente        4.5\n2 presente       5.5\n\n\nCódigo\n# Genero una table resumen de promedios. \n# GLEX11.res<-aggregate(list(talla=GLEX11$talla), \n#                      list(proteina=GLEX11$proteina,\n#                           alcaloide=GLEX11$alcaloide), mean)\n\nGLEX11 %>% group_by(proteina, alcaloide) %>%\n           summarize(promedio = mean(talla, na.rm=TRUE)) %>%\n           pivot_wider(names_from = proteina, values_from = promedio)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  <fct>     <dbl> <dbl> <dbl>\n1 ausente     4.5   3.5   5.5\n2 presente    6.5   7     3"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#exploración-de-varianzas",
    "href": "posts/dis-comp-aleat/index.html#exploración-de-varianzas",
    "title": "Experimentos completamente aleatorizados",
    "section": "Exploración de varianzas",
    "text": "Exploración de varianzas\n\n\nCódigo\n#aggregate(list(talla=GLEX11$talla),\n#          list(proteina=GLEX11$proteina),var) \nGLEX11 %>% group_by(proteina) %>%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 3 × 2\n  proteina   var\n  <ord>    <dbl>\n1 bajo      2.57\n2 medio     4.5 \n3 alto      3.36\n\n\nCódigo\n#aggregate(list(talla=GLEX11$talla), \n#          list(alcaloide=GLEX11$alcaloide), var) \nGLEX11 %>% group_by(alcaloide) %>%\n           summarize(var = var(talla, na.rm=TRUE))\n\n\n# A tibble: 2 × 2\n  alcaloide   var\n  <fct>     <dbl>\n1 ausente    2.09\n2 presente   4.64\n\n\nCódigo\n# tapply(GLEX11$talla, list(GLEX11$proteina, GLEX11$alcaloide), var)\nGLEX11 %>% group_by(proteina, alcaloide) %>%\n           summarize(var = var(talla, na.rm=TRUE)) %>%\n           pivot_wider(names_from = proteina, values_from = var)\n\n\n`summarise()` has grouped output by 'proteina'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 4\n  alcaloide  bajo medio  alto\n  <fct>     <dbl> <dbl> <dbl>\n1 ausente    1.67 1.67   1.67\n2 presente   1.67 0.667  2"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#gráficas-exploratorias",
    "href": "posts/dis-comp-aleat/index.html#gráficas-exploratorias",
    "title": "Experimentos completamente aleatorizados",
    "section": "Gráficas exploratorias",
    "text": "Gráficas exploratorias\n\n\nCódigo\ninteraction.plot(GLEX11$proteina, GLEX11$alcaloide, GLEX11$talla) \n\n\n\n\n\nCódigo\n#args(interaction.plot)"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#ajuste-de-modelos",
    "href": "posts/dis-comp-aleat/index.html#ajuste-de-modelos",
    "title": "Experimentos completamente aleatorizados",
    "section": "Ajuste de modelos",
    "text": "Ajuste de modelos\n\n\nCódigo\nlarvas.nulo <- lm(talla ~ 1, data=GLEX11)\n\n# defino una simple función que extrae devianza y df de un ajuste y lo despliga\n\n# mediante la función \"cat\"\n\ndevianza <- function(x) \n  { cat(\"devianza=\", deviance(x), \"\\ndf=\",x$df.residual,\"\\n\")}\n\n# devianza del modelo nulo\n\ndevianza(larvas.nulo)\n\n\ndevianza= 80 \ndf= 23 \n\n\nCódigo\n# modelo completo\n\nlarvas.completo <- update(larvas.nulo, . ~ . + proteina + alcaloide + proteina:alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\nOtra forma de escribir el modelo completo\n\n\nCódigo\nlarvas.completo <- update(larvas.nulo, . ~ . + proteina * alcaloide) \n\ndevianza(larvas.completo) \n\n\ndevianza= 28 \ndf= 18 \n\n\nCódigo\ncoefficients(larvas.completo)\n\n\n                 (Intercept)                   proteina.L \n                   4.5000000                    0.7071068 \n                  proteina.Q            alcaloidepresente \n                   1.2247449                    1.0000000 \nproteina.L:alcaloidepresente proteina.Q:alcaloidepresente \n                  -3.1819805                   -3.0618622 \n\n\n\n\n¿Significancia de los términos?\n\n\nCódigo\nanova(larvas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: talla\n                   Df Sum Sq Mean Sq F value    Pr(>F)    \nproteina            2      7  3.5000  2.2500 0.1342177    \nalcaloide           1      6  6.0000  3.8571 0.0651695 .  \nproteina:alcaloide  2     39 19.5000 12.5357 0.0003888 ***\nResiduals          18     28  1.5556                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nComparaciones múltiples\nEsto es equivalente a una búsqueda, algo exploratoria, para dar respuesta a la pregunta: ¿Son necesarios todos los niveles de los factores?\n\n\nCódigo\nsummary(larvas.completo)\n\n\n\nCall:\nlm(formula = talla ~ proteina + alcaloide + proteina:alcaloide, \n    data = GLEX11)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.500 -1.000  0.000  0.625  2.000 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                    4.5000     0.3600  12.499 2.61e-10 ***\nproteina.L                     0.7071     0.6236   1.134  0.27172    \nproteina.Q                     1.2247     0.6236   1.964  0.06517 .  \nalcaloidepresente              1.0000     0.5092   1.964  0.06517 .  \nproteina.L:alcaloidepresente  -3.1820     0.8819  -3.608  0.00201 ** \nproteina.Q:alcaloidepresente  -3.0619     0.8819  -3.472  0.00272 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.247 on 18 degrees of freedom\nMultiple R-squared:   0.65, Adjusted R-squared:  0.5528 \nF-statistic: 6.686 on 5 and 18 DF,  p-value: 0.001103\n\n\nCódigo\n# Generación de un factor re-codificado: tomaré: bame = bajo y medio, alto=alto\n\n# Por supuesto hay que considerar que esta fusión tenga sentido biológico.\n\n# Así podemos recodificar el factor proteína.\n\nGLEX11$proteinaBM <- GLEX11$proteina \nlevels(GLEX11$proteinaBM) <- c(\"bame\", \"bame\", \"alto\") # cuidar el orden\n\n\n\nnuevo ajuste de modelo completo con el factor proteina recodificado.\n\n\nCódigo\nlarvas.protBM <- lm(talla ~ proteinaBM * alcaloide, data = GLEX11) \n\nsummary(larvas.protBM)\n\n\n\nCall:\nlm(formula = talla ~ proteinaBM * alcaloide, data = GLEX11)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n    -2     -1      0      1      2 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                      4.7500     0.3781  12.562 6.03e-11 ***\nproteinaBM.L                     1.0607     0.5347   1.984   0.0612 .  \nalcaloidepresente                0.1250     0.5347   0.234   0.8175    \nproteinaBM.L:alcaloidepresente  -3.7123     0.7562  -4.909 8.47e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.235 on 20 degrees of freedom\nMultiple R-squared:  0.6188,    Adjusted R-squared:  0.5616 \nF-statistic: 10.82 on 3 and 20 DF,  p-value: 0.000194\n\n\n\n\n¿qué significancia tiene este cambio en el modelo?\n\n\nCódigo\nanova(larvas.protBM,larvas.completo) \n\n\nAnalysis of Variance Table\n\nModel 1: talla ~ proteinaBM * alcaloide\nModel 2: talla ~ proteina + alcaloide + proteina:alcaloide\n  Res.Df  RSS Df Sum of Sq      F Pr(>F)\n1     20 30.5                           \n2     18 28.0  2       2.5 0.8036 0.4632\n\n\nCódigo\nplot(larvas.protBM) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ntapply(GLEX11$talla, list(GLEX11$proteinaBM, GLEX11$alcaloide), mean) \n\n\n     ausente presente\nbame     4.0     6.75\nalto     5.5     3.00\n\n\nCódigo\nGLEX11.resBM <- aggregate(list(talla = GLEX11$talla), \n                          list(proteinaBM= GLEX11$proteinaBM, \n                               alcaloide = GLEX11$alcaloide), mean)\n\ninteraction.plot(GLEX11$proteinaBM, GLEX11$alcaloide, GLEX11$talla)"
  },
  {
    "objectID": "posts/dis-comp-aleat/index.html#conclusiones",
    "href": "posts/dis-comp-aleat/index.html#conclusiones",
    "title": "Experimentos completamente aleatorizados",
    "section": "Conclusiones",
    "text": "Conclusiones\nCon base en estos análisis ¿Cual es el modelo mínimo adecuado?. ¿cómo podemos interpretar estos resultados? ¿tienen sentido o relevancia?"
  },
  {
    "objectID": "posts/evaluacion/index.html",
    "href": "posts/evaluacion/index.html",
    "title": "Evaluación",
    "section": "",
    "text": "El Módulo III será evaluado a través de las tareas y controles de lectura que les pediremos que hagan conforme se desarrolle el curso. La participación en quizes y preguntas en línea será considerada como una oportunidad de mejora, aunque la no participación no se considerará para disminuir la calificación."
  },
  {
    "objectID": "posts/experimentos-anidados/index.html#ejemplo-control-del-glucógeno-en-hígados-de-rata",
    "href": "posts/experimentos-anidados/index.html#ejemplo-control-del-glucógeno-en-hígados-de-rata",
    "title": "Modelos anidados",
    "section": "Ejemplo: Control del glucógeno en hígados de rata",
    "text": "Ejemplo: Control del glucógeno en hígados de rata\nEste ejemplo presentado originalmente en Sokal & Rohlf (1981). Se trata de un experimento con un solo factor con tres dietas: 1 = “control”, 2 = “compuesto 217”, 3 = “compuesto 217 + azúcar”. Fueron administrados a seis ratas, dos por tratamiento. El análisis se complica por el hecho de que, para el análisis, se tomaron tres muestras del hígado de cada rata y se hicieron dos determinaciones de contenido de glucógeno en cada muestra. Así, hay seis parcelas chicas (lo que a algunos les gusta llamar pseudorréplicas) en cada rata, para finalmente dar 36 lecturas en total.\n\n\nCódigo\nglucog_rata <- dagitty('dag{trat -> rata\n                            rata -> hig\n                             hig -> muest\n                             muest -> gluc\n                             trat -> gluc\n                             rata -> gluc\n                             trat -> hig\n                             trat -> muest\n                             hig -> gluc\n                             muest -> gluc}')\n\npar(cex = 2, lwd  = 5)\nplot(glucog_rata)\n\n\nPlot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own.\n\n\n\n\n\nArreglé el código para incorporar la versión con la tubo-metáfora. haciendo esto me encontré este artículo quejoso al respecto. Ni modo, comparto algo del punto de vista de ese autor.\n\n\nCódigo\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nratas <- as_tibble(read.table(\"GLEX38.DAT\",                 \n                    col.names=\"glucogeno\"))\n\nratas <- ratas %>% \n               mutate(tratamiento = factor(rep(1:3,each=12), levels=c(1:3)),\n               rata = factor(rep(1:2,times=3, each=6), levels=c(1,2)),\n               muestraH = factor(rep(1:3,times=6, each=2), levels=c(1:3)))\n\n#ratas$tratamiento <- factor(rep(1:3,each=12), levels=c(1:3))\n#ratas$rata <- factor(rep(1:2,times=3, each=6), levels=c(1,2))\n#ratas$muestraH <- factor(rep(1:3,times=6, each=2), levels=c(1:3))\nhead(ratas)\n\n\n# A tibble: 6 × 4\n  glucogeno tratamiento rata  muestraH\n      <int> <fct>       <fct> <fct>   \n1       131 1           1     1       \n2       130 1           1     1       \n3       131 1           1     2       \n4       125 1           1     2       \n5       136 1           1     3       \n6       142 1           1     3"
  },
  {
    "objectID": "posts/experimentos-anidados/index.html#inspección-de-los-datos",
    "href": "posts/experimentos-anidados/index.html#inspección-de-los-datos",
    "title": "Modelos anidados",
    "section": "inspección de los datos",
    "text": "inspección de los datos\n\n\nCódigo\ntapply (ratas$glucogeno, list(ratas$tratamiento), mean)\n\n\n       1        2        3 \n140.5000 151.0000 135.1667 \n\n\nQuizás es mala idea etiquetar a los factores en forma numérica cuando hay la posibilidad de darles un nombre que nos facilite interpretar los resultados, especialmente para los efectos fijos. Cambiemos eso para los tratamientos. Hay varias formas de hacer esto, unas más seguras que otras, pero en este caso el cambio es muy sencillo y lo podemos hacer con suficiente seguridad como lo hemos venido haciendo con la función levels. Pero para atender casos más complejos sugiero usar la biblioteca tidyverse así.\n\n\nCódigo\nratas <- ratas %>% mutate(trat_txt=recode(tratamiento, \n                                          \"1\"=\"trat_1\", \n                                          \"2\"=\"trat_2\", \n                                          \"3\"=\"trat_3\"))\n\nhead(ratas)\n\n\n# A tibble: 6 × 5\n  glucogeno tratamiento rata  muestraH trat_txt\n      <int> <fct>       <fct> <fct>    <fct>   \n1       131 1           1     1        trat_1  \n2       130 1           1     1        trat_1  \n3       131 1           1     2        trat_1  \n4       125 1           1     2        trat_1  \n5       136 1           1     3        trat_1  \n6       142 1           1     3        trat_1"
  },
  {
    "objectID": "posts/experimentos-anidados/index.html#ajuste-de-modelo",
    "href": "posts/experimentos-anidados/index.html#ajuste-de-modelo",
    "title": "Modelos anidados",
    "section": "Ajuste de modelo",
    "text": "Ajuste de modelo\nEn este caso tengo una estructura anidada, así que hay podemos usar el operador de anidación %in%. Sin embargo, hay que tener cuidado, pues esto sólo añade el efecto de anidamiento especificado, no los términos principales u otros niveles de anidamiento que pudieran estar presentes. También hay que notar que un anidamiento equivale en el modelo estadístico lineal a la presencia de términos de interacción sin su contraparte de términos en la jerarquía. En este caso, no aparece ninguna interacción tratamiento:rata o tratamiento:muestraHígado, etc., pero sí aparecen las interacciones más complejas: rata:muestraHígado:tratamieno por ejemplo.\n\n\nCódigo\nratas.completo <- lm(glucogeno ~ trat_txt + rata + muestraH + muestraH %in% rata + muestraH %in% rata %in% tratamiento, data=ratas)\nsummary(ratas.completo)\n\n\n\nCall:\nlm(formula = glucogeno ~ trat_txt + rata + muestraH + muestraH %in% \n    rata + muestraH %in% rata %in% tratamiento, data = ratas)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.00  -2.25   0.00   2.25   6.00 \n\nCoefficients: (2 not defined because of singularities)\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   130.500      3.253  40.114  < 2e-16 ***\ntrat_txttrat_2                  2.000      4.601   0.435 0.668937    \ntrat_txttrat_3                -24.500      4.601  -5.325 4.62e-05 ***\nrata2                          18.500      4.601   4.021 0.000801 ***\nmuestraH2                      -2.500      4.601  -0.543 0.593526    \nmuestraH3                       8.500      4.601   1.848 0.081172 .  \nrata2:muestraH2                -5.000      6.506  -0.768 0.452171    \nrata2:muestraH3                -2.500      6.506  -0.384 0.705305    \nrata1:muestraH1:tratamiento2   18.500      6.506   2.843 0.010785 *  \nrata2:muestraH1:tratamiento2    2.000      6.506   0.307 0.762075    \nrata1:muestraH2:tratamiento2   18.000      6.506   2.767 0.012716 *  \nrata2:muestraH2:tratamiento2    3.500      6.506   0.538 0.597214    \nrata1:muestraH3:tratamiento2    9.000      6.506   1.383 0.183506    \nrata2:muestraH3:tratamiento2       NA         NA      NA       NA    \nrata1:muestraH1:tratamiento3   23.500      6.506   3.612 0.001994 ** \nrata2:muestraH1:tratamiento3   14.500      6.506   2.229 0.038828 *  \nrata1:muestraH2:tratamiento3   34.500      6.506   5.302 4.85e-05 ***\nrata2:muestraH2:tratamiento3   21.500      6.506   3.304 0.003943 ** \nrata1:muestraH3:tratamiento3   21.000      6.506   3.228 0.004670 ** \nrata2:muestraH3:tratamiento3       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.601 on 18 degrees of freedom\nMultiple R-squared:  0.8856,    Adjusted R-squared:  0.7775 \nF-statistic: 8.196 on 17 and 18 DF,  p-value: 2.508e-05\n\n\n\n\nCódigo\n#tapply (ratas$glucogeno, list(ratas$trat_txt), mean)\nratas %>% group_by(trat_txt) %>% summarise(media = mean(glucogeno))\n\n\n# A tibble: 3 × 2\n  trat_txt media\n  <fct>    <dbl>\n1 trat_1    140.\n2 trat_2    151 \n3 trat_3    135.\n\n\nCódigo\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                          Df  Sum Sq Mean Sq F value    Pr(>F)    \ntrat_txt                   2 1557.56  778.78 36.7927 4.375e-07 ***\nrata                       1  413.44  413.44 19.5328 0.0003308 ***\nmuestraH                   2  113.56   56.78  2.6824 0.0955848 .  \nrata:muestraH              2   50.89   25.44  1.2021 0.3235761    \nrata:muestraH:tratamiento 10  813.78   81.38  3.8446 0.0063654 ** \nResiduals                 18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nRecuerda que las pruebas omnibus del ANOVA de arriba sólo tienen sentido en cuanto a comparación de medias, para los términos de efectos fijos.\n¿Cómo interpretas estos resultados\nConviene saber que hay muuchas maneras de hacer lo mismo en R. esta es otra forma de lograr exactamente lo mismo, pero utilizando otra notación en la forma de escribir las ecuaciones al utilizar la función de ajuste de modelos lineales.\n\n\nCódigo\nratas.nulo <- lm(glucogeno~1, data=ratas)\nratas.completo <- lm(glucogeno ~ trat_txt/rata/muestraH, data=ratas)\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                       Df  Sum Sq Mean Sq F value    Pr(>F)    \ntrat_txt                2 1557.56  778.78 36.7927 4.375e-07 ***\ntrat_txt:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntrat_txt:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals              18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\nsummary(ratas.completo)\n\n\n\nCall:\nlm(formula = glucogeno ~ trat_txt/rata/muestraH, data = ratas)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.00  -2.25   0.00   2.25   6.00 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                     130.500      3.253  40.114  < 2e-16 ***\ntrat_txttrat_2                   20.500      4.601   4.456 0.000305 ***\ntrat_txttrat_3                   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_1:rata2             18.500      4.601   4.021 0.000801 ***\ntrat_txttrat_2:rata2              2.000      4.601   0.435 0.668937    \ntrat_txttrat_3:rata2              9.500      4.601   2.065 0.053645 .  \ntrat_txttrat_1:rata1:muestraH2   -2.500      4.601  -0.543 0.593526    \ntrat_txttrat_2:rata1:muestraH2   -3.000      4.601  -0.652 0.522595    \ntrat_txttrat_3:rata1:muestraH2    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_1:rata2:muestraH2   -7.500      4.601  -1.630 0.120438    \ntrat_txttrat_2:rata2:muestraH2   -6.000      4.601  -1.304 0.208616    \ntrat_txttrat_3:rata2:muestraH2   -0.500      4.601  -0.109 0.914660    \ntrat_txttrat_1:rata1:muestraH3    8.500      4.601   1.848 0.081172 .  \ntrat_txttrat_2:rata1:muestraH3   -1.000      4.601  -0.217 0.830375    \ntrat_txttrat_3:rata1:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_1:rata2:muestraH3    6.000      4.601   1.304 0.208616    \ntrat_txttrat_2:rata2:muestraH3    4.000      4.601   0.869 0.396059    \ntrat_txttrat_3:rata2:muestraH3   -8.500      4.601  -1.848 0.081172 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.601 on 18 degrees of freedom\nMultiple R-squared:  0.8856,    Adjusted R-squared:  0.7775 \nF-statistic: 8.196 on 17 and 18 DF,  p-value: 2.508e-05\n\n\nuso de la función de análisis de la varianza de R\n\n\nCódigo\nratas.aov <- aov(glucogeno ~ tratamiento/rata/muestraH, data=ratas)\nsummary(ratas.aov)\n\n\n                          Df Sum Sq Mean Sq F value   Pr(>F)    \ntratamiento                2 1557.6   778.8  36.793 4.38e-07 ***\ntratamiento:rata           3  797.7   265.9  12.562 0.000114 ***\ntratamiento:rata:muestraH 12  594.0    49.5   2.339 0.050291 .  \nResiduals                 18  381.0    21.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCódigo\nanova(ratas.completo)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                       Df  Sum Sq Mean Sq F value    Pr(>F)    \ntrat_txt                2 1557.56  778.78 36.7927 4.375e-07 ***\ntrat_txt:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntrat_txt:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals              18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComo hemos dicho, en realidad la estructura de estos datos es mixta en cuanto a que incluye efectos fijos de los tratamientos y efectos aleatorios. Contiene los efectos aleatorios de la muestra que constituyen las ratas y dentro de ellas el muestreo de porciones de hígado. Así, la prueba F para el efecto de tratamientos es de interés pero, en el caso de los factores aleatorios puede valer la pena estimar los componentes de varianza asociados con cada etapa de muestreo. Una manera de hacer esto es mediante la función aov de R, dentro de la cual sólo es necesario designar las columnas que corresponden con efectos aleatorios mediante la función Error(). Estto funciona bien si el experimento es completo y balanceado.\n\n\nCódigo\nratas.aov <- aov(glucogeno ~ tratamiento/rata/muestraH + \n                 Error(rata + muestraH + rata/muestraH), data=ratas)\nsummary(ratas.aov)\n\n\n\nError: rata\n                 Df Sum Sq Mean Sq\ntratamiento:rata  1  413.4   413.4\n\nError: muestraH\n                          Df Sum Sq Mean Sq\ntratamiento:rata:muestraH  2  113.6   56.78\n\nError: rata:muestraH\n                          Df Sum Sq Mean Sq\ntratamiento:rata:muestraH  2  50.89   25.44\n\nError: Within\n                          Df Sum Sq Mean Sq F value   Pr(>F)    \ntratamiento                2 1557.6   778.8  36.793 4.38e-07 ***\ntratamiento:rata           2  384.2   192.1   9.076  0.00188 ** \ntratamiento:rata:muestraH  8  429.6    53.7   2.537  0.04813 *  \nResiduals                 18  381.0    21.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/leyes-de-la-ciencia/index.html",
    "href": "posts/leyes-de-la-ciencia/index.html",
    "title": "Leyes de la Ciencia",
    "section": "",
    "text": "En esta primera sesión les proponemos reflexionar sobre la intención o incluso necesidad de recurrir a enfoques numéricos o matemáticos para hacer ciencia. También, debemos considerar el propósito mismo de la actividad científica en la que estamos involucrados. Cuando hablamos de generación de conocimiento, ¿realmente a qué nos estamos refiriendo?. Podríamos considerar que la producción de conocimiento involucra la formulación de expresiones matemáticas. Con estas expresiones podemos describir la existencia de relaciones específicas entre procesos que observamos. ¿es esto así? Si es el caso, ¿es la única manera de hacerlo?. Si consideramos que nos es la única, entonces cabe preguntarnos ¿es la mejor manera de hacerlo?. Estas y otras inquietudes de este tipo serán el tema de reflexión y hasta debate si quieren en esta primera sesión.\n\nParticipación activa\nHemos previsto tener frecuentes eventos interactivos para dar seguimiento a los temas que iremos tratando o para generar espacios de enfoque que nos ayuden a generar contextos de discusión que nos ayuden a reflexionar sobre cómo es que hacemos ciencia. Para hacer esto utilizaremos la aplicación en línea a la que podrán acceder desde sus computadoras o teléfonos celulares mediante el siguiente vínculo: https://vevox.app/#/m/188445929 o recurriendo al siguiente código QR.\n\n\n\nApoyo audiovisual de la sesión\nA continuación encontraran la presentación que usaremos como apoyo audiovisual para conducir la exploración de los temas que discutiremos en esta sesión."
  },
  {
    "objectID": "posts/modelo-lineal/index.html",
    "href": "posts/modelo-lineal/index.html",
    "title": "El Modelo estadístico lineal",
    "section": "",
    "text": "El diseño, análisis y reporte de los resultados de experimentos o estudios en general tiene un vínculo muy estrecho con la modelación estadística. Las hipótesis de investigación deben ser expresadas de modo tal que sean suceptibles de ser valoradas con apoyo estadístico y a partir de ahí, el análiisis de los datos y el reporte de resultados hacen referencia obligada a los atributos de los modelos estudiados, desde luego considerando su correspondencia o falta de ella, con los datos obtenidos en el estudio y las ideas que el equipo de investigación se ha propuesto desentrañar. Es así como usualmente se aplica la llamada prueba de hipótesis que se basa en la comparación y selección de modelos, buscando encontrar aquellos que ofrezcan la mejor correspondencia con una explicación plausible del proceso que genera datos semejantes a los que se utilizaron en el estudio. En esta sesión abordaremos esta temática."
  },
  {
    "objectID": "posts/modelos-mixtos/index.html#ejemplo-de-rieles",
    "href": "posts/modelos-mixtos/index.html#ejemplo-de-rieles",
    "title": "Modelos de Efectos Mixtos",
    "section": "Ejemplo de rieles",
    "text": "Ejemplo de rieles\nEs un ejemplo simple de efectos aleatorios que considera los datos de un estudio de medición no destructiva de la resistencia a la tensión de rieles de ferrocarril. Seis rieles fueron tomados al azar y sometidos a prueba tres veces cada uno a través de la medición del tiempo que le toma a cierto tipo de ondas ultrasónicas viajar a lo largo del riel. La Única condición experimental que cambia entre observaciones es el riel.\nClaramente el estudio tiene un solo criterio de clasificación, como condición de contraste. La intención del estudio fue la determinación de: 1. Tiempo de tránsito “típico” de un riel (tiempo esperado de tránsito) 2. Variacián en el tiempo de tránsito promedio entre los rieles (variabilidad entre rieles) 3. Variación en el tiempo observado de tránsito de un riel dado (variabilidad dentro de rieles)\n\\[\ny_{ij} = \\mu + \\beta_{1} R_{i} + \\varepsilon_{i(j)}\n\\]\nLo primero que haremos es preparar las bibliotecas que utilizaremos. En este caso nlme para ajustar los modelos de efectos mixtos y lattice aunque también podría usarse ggplot2 para hacer las gráficas.\nLattice contiene estas opciones:\n\n\n\ntipo de gráfica\ndescripción\nejemplo de fórmula\n\n\n\n\nbarchart\nbar chart\nx~A or A~x\n\n\nbwplot\nboxplot\nx~A or A~x\n\n\ncloud\n3D scatterplot\nz~x*y|A\n\n\ncontourplot\n3D contour plot\nz~x*y\n\n\ndensityplot\nkernal density plot\n~x|A*B\n\n\ndotplot\ndotplot\n~x|A\n\n\nhistogram\nhistogram\n~x\n\n\nlevelplot\n3D level plot\nz~y*x\n\n\nparallel\nparallel coordinates plot\ndata frame\n\n\nsplom\nscatterplot matrix\ndata frame\n\n\nstripplot\nstrip plots\nA~x or x~A\n\n\nxyplot\nscatterplot\ny~x|A\n\n\nwireframe\n3D wireframe graph\nz~y*x\n\n\n\nLas gráficas con lattice tienen todo un entorno de soporte. Por ejemplo los aspectos que pueden ajustarse se pueden ver con trellis.par.get() y se ajustan con trellis.par.set(). Actualmente, resulta quizás más práctico el enfoque que ha desarrollado ggplot2.\nlos datos están en la tabla riel de la biblioteca nlme. La copiamos al espacio de de trabajo y los asigno a una variable con un nombre de mi gusto. Los datos de los rieles están ordenados según fueron ensayados.\n\n\nCódigo\nlibrary(nlme)\nlibrary(lattice)\nlibrary(ggplot2)\n\nrieles <- Rail\nnames(rieles) <- c(\"riel\", \"viaje\")\nstr(rieles)\n\n\nClasses 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"<\"5\"<\"1\"<\"6\"<..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n - attr(*, \"labels\")=List of 1\n  ..$ y: chr \"Zero-force travel time\"\n - attr(*, \"units\")=List of 1\n  ..$ y: chr \"(nanoseconds)\"\n - attr(*, \"formula\")=Class 'formula'  language travel ~ 1 | Rail\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"order.groups\")= logi TRUE\n\n\nLa tabla rieles fue creada como una estructura agrupada con la función groupeData de la biblioteca nlme. Veremos más adelante como usar esta función. Esta funnción agrega metadatos a la tabla. Si interesa hacer cambios a los metadatos de la tabla agrupada hay que usar la función update que ejemplificaré a continuación. Lo primero es explorar los atributos asignados.\n\n\nCódigo\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$labels\n$labels$y\n[1] \"Zero-force travel time\"\n\n\n$units\n$units$y\n[1] \"(nanoseconds)\"\n\n\n$formula\ntravel ~ 1 | Rail\n\n$order.groups\n[1] TRUE\n\n\nAhora cambiemos estos atributos para que todo esté expresado en español y de paso corregir la fórmula, que tal como está, pierde la referencia adecuada a las variables que contiene la tabla, pues cambiamos los nombres de las variables.\n\n\nCódigo\nrieles  <- update(rieles, formula = viaje ~ 1 | riel, FUN = mean,\n                  labels = list(y = \"Tiempo de viaje con fuerza cero\"),\n                  units = list(y = \"(nano segundos)\"))\n\n# Encontré un detallito raro de atributos que se quedan con basura. \n# Aunque no parecen producir ning´nu problema, esta es una manera de limpiarla.\nattributes(attributes(rieles)$formula)$\".Environment\" <- environment()\nenvironment(attributes(rieles)$FUN) <- environment()\nattributes(rieles)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"nffGroupedData\" \"nfGroupedData\"  \"groupedData\"    \"data.frame\"    \n\n$formula\nviaje ~ 1 | riel\n\n$labels\n$labels$y\n[1] \"Tiempo de viaje con fuerza cero\"\n\n\n$units\n$units$y\n[1] \"(nano segundos)\"\n\n\n$FUN\nfunction (x, ...) \nUseMethod(\"mean\")\n\n$order.groups\n[1] TRUE\n\n\nA esta tabla se le ha aplicado la función groupedData con la fórmula:\nviaje ~ 1| riel\nEsta estrategia permite darle mantenimiento a los metadatos, que incluyen indicaciones sobre el agrupamiento de los datos en la tablas. Para aprovechar esta estructura podemos usar funciones especiales, por cierto, dentro del paquete nmle, la función plo ha sido diseñada para usar opciones de graficación de latice, puedes averiguar un poco más al respecto con help(plot.nmGroupedData):\n\ngapply - aplica funciones por grupos\ngsummary - calcula los resúmenes de datos por grupos\n\nPor lo pronto veamos los datos, con la función de graficación de lattice stripplot, que toma el factor riel, por lo tanto se trata de renglones cualitativos sobre los que se grafican los datos de velocidad de viaje.\n\n\nCódigo\noptions(repr.plot.width=10, repr.plot.height=6)\n\nstripplot(rieles$riel ~ rieles$viaje, pch = 19, col = \"red\", cex = 1.25,\n          main = list(label = \"Análisis de integridad estructural de rieles\", cex =2),\n          xlab = list(label = \"tiempo de viaje (ns)\", cex = 2),\n          ylab =  list(label = \"riel\", cex = 2), \n          scales = list(tck = c(2,0), x = list(cex = 2), y = list(cex = 2)))\n\n\n\n\n\n¿Cómo se ven estos datos? ¿qué piensas que habría que hacer?\n\n\nCódigo\nggplot(rieles, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\n\n\nCódigo\ngsummary(rieles)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n¿Cómo se asigna la estructura de agrupación a una tabla de datos? Como dije al principio, se puede usar la función groupedData de la biblioteca nlme. Hagamos un ahora un ensayo de este proceso.\n\n\nCódigo\nrieles.sg <- as.data.frame(rieles)\n\n\nEstructura de la tabla sin información de agrupamiento:\n\n\nCódigo\nstr(rieles.sg) \n\n\n'data.frame':   18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"<\"5\"<\"1\"<\"6\"<..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n\n\nLos atributos quue contiene este objeto son estos:\n\n\nCódigo\nattributes(rieles.sg)\n\n\n$names\n[1] \"riel\"  \"viaje\"\n\n$row.names\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\"\n\n$class\n[1] \"data.frame\"\n\n\nTomo los datos sin agrupamiento y proporciono los metadatos que definen la estructura de agrupamiento que caracterizan a la tabla :\n\n\nCódigo\nrieles.g <- groupedData (viaje ~ 1 | riel, data = rieles.sg, \n                         FUN = mean,\n                         units = list( x = \"(ns)\"),\n                         labels = list(x = \"riel\", \n                                       y = \"tiempo de tránsito de fuerza cero\"),\n                         )\nstr(rieles.g)\n\n\nClasses 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  18 obs. of  2 variables:\n $ riel : Ord.factor w/ 6 levels \"2\"<\"5\"<\"1\"<\"6\"<..: 3 3 3 1 1 1 5 5 5 6 ...\n $ viaje: num  55 53 54 26 37 32 78 91 85 92 ...\n - attr(*, \"formula\")=Class 'formula'  language viaje ~ 1 | riel\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"riel\"\n  ..$ y: chr \"tiempo de tránsito de fuerza cero\"\n - attr(*, \"units\")=List of 1\n  ..$ x: chr \"(ns)\"\n - attr(*, \"FUN\")=function (x, ...)  \n - attr(*, \"order.groups\")= logi TRUE\n\n\n\n\nCódigo\ndata.frame(sg=rieles.sg, g=rieles.g)\n\n\n   sg.riel sg.viaje g.riel g.viaje\n1        1       55      1      55\n2        1       53      1      53\n3        1       54      1      54\n4        2       26      2      26\n5        2       37      2      37\n6        2       32      2      32\n7        3       78      3      78\n8        3       91      3      91\n9        3       85      3      85\n10       4       92      4      92\n11       4      100      4     100\n12       4       96      4      96\n13       5       49      5      49\n14       5       51      5      51\n15       5       50      5      50\n16       6       80      6      80\n17       6       85      6      85\n18       6       83      6      83\n\n\n\n\nCódigo\ngsummary(rieles.sg)\n\n\n    riel viaje\n26     2    26\n32     2    32\n37     2    37\n49     5    49\n50     5    50\n51     5    51\n53     1    53\n54     1    54\n55     1    55\n78     3    78\n80     6    80\n83     6    83\n85     3    85\n91     3    91\n92     4    92\n96     4    96\n100    4   100\n\n\n\n\nCódigo\ngsummary(rieles.g)\n\n\n  riel    viaje\n2    2 31.66667\n5    5 50.00000\n1    1 54.00000\n6    6 82.66667\n3    3 84.66667\n4    4 96.00000\n\n\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       geom_point(shape = 19, size = 4, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles (rieles.g)\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\nComo hemos visto, cambiar los metadatos de la tabla se hace con la función update().\nComo una demostración simple de esto, le cambiaré la etiqueta asociada a la variable de respuesta en la estrucutra de agrupamiento. Con esto.\n\n\nCódigo\nrieles.g1 <- update(rieles.g, labels = list(y=\"tiempo (ns)\"))\nplot(rieles.g1)\n\n\n\n\n\nPrimera posibilidad de análisis. Modelo lineal simple. Es una elección natural en este caso, pues estima la media general. Hay que recordar seleccionar contrastes de tipo “tratamiento” aun para factores ordenados.\n¿Cómo representamos al riel en el modelo?\n\n\nCódigo\noptions ()$contrasts\n\n\n        unordered           ordered \n\"contr.treatment\"      \"contr.poly\" \n\n\nEmpecemos por construir el modelo nulo. ¿qué resultados nos ofrece este modelo?.\n\n\nCódigo\nrieles.m1 <- lm(viaje ~ 1, data =rieles.g)\nsummary(rieles.m1)\n\n\n\nCall:\nlm(formula = viaje ~ 1, data = rieles.g)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40.50 -16.25   0.00  18.50  33.50 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   66.500      5.573   11.93  1.1e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.65 on 17 degrees of freedom\n\n\nAsí, tengo una estimación del tiempo promedio de tránsito de: 66.5. El error estándar que estimo es: 5.573\n¿cómo quedan los residuos de este modelo?\nEl gráfico de cajas y bigotes o cajas y alambres es interesante para explorar lo que está pasando con los rieles. La versión que produce la función bwplot() de la biblioteca lattice es un buen recurso.\n¿Qué piensas de esta gráfica? ¿Te gusta lo que ves?\n\n\nCódigo\nbwplot(rieles.g$riel ~ resid(rieles.m1))\n\n\n\n\n\n\n\nCódigo\nggplot(rieles.g, aes(x = viaje, y = riel, group = riel)) + \n       stat_boxplot(geom='errorbar', linetype=2, width=0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\") +\n       labs(title = \"Análisis de integridad estructural de rieles (rieles.g)\") +\n       xlab(label = \"tiempo de viaje (ns)\") +\n       ylab(label = \"riel\") +\n       theme(text = element_text(size=26), \n             axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\nAl ignorar el efecto de los rieles, dentro de los que repito la prueba para obtener las medidas de interés se produce un defecto que se ve claramente en esta gráfica de residuos.\nLos residuos de cada riel tienen todos el mismo signo. Es decir se mantiene un efecto sistemático importante en ellos.\nTe parecería buena idea agregar el término que representa al riel para resolver este problema?\n¿Es fijo o aleatorio?\nEste nuevo modelo permite que cada riel sea representado por una media diferente. Suponiendo efectos fijos, la estimación del parámetro de interés es esta.\n\n\nCódigo\nrieles.m2 <- lm(viaje ~ riel - 1, data =rieles.g)\nrieles.m2\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nCoefficients:\nriel2  riel5  riel1  riel6  riel3  riel4  \n31.67  50.00  54.00  82.67  84.67  96.00  \n\n\n\n\nCódigo\nanova(rieles.m2)\n\n\nAnalysis of Variance Table\n\nResponse: viaje\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nriel       6  88911 14818.5  916.61 2.971e-15 ***\nResiduals 12    194    16.2                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCódigo\nsummary(rieles.m2)\n\n\n\nCall:\nlm(formula = viaje ~ riel - 1, data = rieles.g)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6667 -1.0000  0.1667  1.0000  6.3333 \n\nCoefficients:\n      Estimate Std. Error t value Pr(>|t|)    \nriel2   31.667      2.321   13.64 1.15e-08 ***\nriel5   50.000      2.321   21.54 5.86e-11 ***\nriel1   54.000      2.321   23.26 2.37e-11 ***\nriel6   82.667      2.321   35.61 1.54e-13 ***\nriel3   84.667      2.321   36.47 1.16e-13 ***\nriel4   96.000      2.321   41.35 2.59e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 12 degrees of freedom\nMultiple R-squared:  0.9978,    Adjusted R-squared:  0.9967 \nF-statistic: 916.6 on 6 and 12 DF,  p-value: 2.971e-15\n\n\n¿interpretación de este nuevo resultado?\n……….. ¿y los residuos? ¿cómo se ven ahora?\n\n\nCódigo\nbwplot(rieles.g$riel ~ resid(rieles.m2))\n\n\n\n\n\n\n\nCódigo\nres.m2 <- data.frame(resid = resid(rieles.m2), riel = rieles.g$riel)\nggplot(res.m2, aes(x = resid, y = riel, group = riel)) + \n       stat_boxplot(geom='errorbar', linetype=2, width=0.5) + \n       geom_boxplot(shape = 19, size = 0.5, color = \"blue\") \n\n\n\n\n\nA pesar de que el modelo remueve los efectos sistemáticos asociados a las características particulares de los distintos rieles, no proporciona una representación satisfactoria del problema.\nsi los rieles son de efectos fijos ¿qué implica este modelo? ¿qué sería el tratamiento riel?_\nAl suponer efectos fijos surge el problema de que se modelan de algún modo variantes individuales de los rieles que se usaron para realizar las pruebas. Desafortunadamente, tal clasificación no tiene ningún sentido en el contexto. Lo que interesa es estimar el tiempo de tránsito típico de cualquier riel en la población de rieles de la que se tomó la muestra.\nAdemás, la misma falta de correspondencia conceptual entre el modelo y la estimación que interesa, hace que este nuevo modelo no proporcione una clara estimación de la variación (componente de varianza), entre rieles, que es otra de las preguntas centrales de este estudio. Otro problema de este modelo de efectos fijos es que el número de parámetros crece linealmente con el número de rieles que se usan para realizar la prueba, generando un comportamiento extraño en el modelo respecto de la pregunta.\n\nEl Modelo de efectos aleatorios ¿resuelves estos problemas?.\nEn este enfoque se considera a los rieles como un efecto aleatorio sobre la media general. Hay principalmente dos métodos para ajustar este tipo de modelos el de máxima verosimilitud (ML) y el de máxima verosimilitud restringida (REML, default). La función que utilizaremos para el caso lineal es lme() que se usa de modo muy semejante a lm() y glm(). Sin embargo, nótese que ahora el modelo tiene dos grupos de fórmulas, una para describir los efectos fijos (opción fixed) y otra para describir los aleatorios (opción random). Esté último es siempre una fórmula que tiene sólo el lado derecho (no hay interés en predecir medias, ¿recuerdas?) y da cuenta de los efectos aleatorios y de la estructura de agrupamiento de los datos. Un agrupamiento se representa mediante el símbolo de barra vertical: |. Ahora, ajustemos un modelo de este tipo para obtener la estimación de máxima verosimilitud restringida para los rieles.\n\n\nCódigo\nrieles.m3 <- lme(fixed = viaje ~ 1, \n                 random = ~ 1 | riel, \n                 data = rieles.g)\nrieles.m3\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n  Log-restricted-likelihood: -61.0885\n  Fixed: viaje ~ 1 \n(Intercept) \n       66.5 \n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nNumber of Observations: 18\nNumber of Groups: 6 \n\n\nAyudame a comentar estos resultados ¿qué te llama la atención?\n\n\nCódigo\nsummary (rieles.m3)\n\n\nLinear mixed-effects model fit by REML\n  Data: rieles.g \n      AIC      BIC   logLik\n  128.177 130.6766 -61.0885\n\nRandom effects:\n Formula: ~1 | riel\n        (Intercept) Residual\nStdDev:    24.80547 4.020779\n\nFixed effects:  viaje ~ 1 \n            Value Std.Error DF  t-value p-value\n(Intercept)  66.5  10.17104 12 6.538173       0\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.61882658 -0.28217671  0.03569328  0.21955784  1.61437744 \n\nNumber of Observations: 18\nNumber of Groups: 6 \n\n\nEl ajuste produce los estimadores que buscamos: 1. tiempo de tránsito típico = 66.5 2. Variabilidad entre rieles = 24.81 3. Variabilidad dentro de rieles = 4.02\nEn este caso los estimadores 1 y 3 son prácticamente idénticos a los obtenidos con el modelo lineal ordinario, pero esto no siempre es así. La coincidencia deriva de que la muestra está balanceada (mismo tamaño de muestra en cada riel). Además, ahora tengo un razonable estimador de la variación entre rieles (2).\n¿Qué utilidad pueden tener estas estimaciones?\nEl resumen del ajuste muestra dos criterios nuevos para comparar y evaluar modelos. Estas medidas son resultado de la búsqueda de alternativas para valorar modelos que no se centre en el famoso valor de p.\n\nAIC - Criterio de información de Akaike = -2 * logVerosimilitud + 2 numParámetros\nBIC - Criterio de información bayesiano = -2 * logVerosimilitud + numParámetros * log(N)\n\nEs bueno contar con ellos para comparar la calidad general de los modelos ajustados, pero no olviden que centrar nuestra atención en los intervalos de confianza es más informativo y potencialmente interesante.\nEn cualquier caso, “entre más pequeño el valor del criterio, mejor”, pero no olvides que más interesantes son los intervalos de confianza que obtengas.Finalmente, veamos los residuos\n¿Cómo se ven?\n¿Qué nos sugieren estos resultados?\n\n\nCódigo\nbwplot(rieles.g$riel ~ resid(rieles.m3))\n\n\n\n\n\nPuedo obtener los estimadores de los coeficientes igual que en el caso lm() y glm() con coef(), pero además puedo obtener los coeficientes de los componentes aleatorios con random.effects() (forma breve: ranef()). ¿Que hay de los intervalos de confianza de los parámetros de efectos fijos estimados?.\nComo he venido insistiendo, esta forma de mostrar resultados es cada vez más apreciada y es más conveniente que el enfoque de uso de valores de “p” en las publicaciones. La función intervals() supone un nivel de confianza del 95%, si no se le dice otra cosa.\n\n\nCódigo\ncoef(rieles.m3)\n\n\n  (Intercept)\n2    31.96909\n5    50.14325\n1    54.10852\n6    82.52631\n3    84.50894\n4    95.74388\n\n\n\n\nCódigo\nranef(rieles.m3)\n\n\n  (Intercept)\n2   -34.53091\n5   -16.35675\n1   -12.39148\n6    16.02631\n3    18.00894\n4    29.24388\n\n\n¿Qué piensas de estos estimadores de intervalos de confianza?\n\n\nCódigo\nintervals(rieles.m3, 0.95)\n\n\nApproximate 95% confidence intervals\n\n Fixed effects:\n               lower est.    upper\n(Intercept) 44.33921 66.5 88.66079\n\n Random Effects:\n  Level: riel \n                   lower     est.    upper\nsd((Intercept)) 13.27434 24.80547 46.35341\n\n Within-group standard error:\n   lower     est.    upper \n2.695007 4.020779 5.998747 \n\n\n\n\nEl modelo de glucógeno en ratas revisitado\nVolvamos a ver el ejemplo GLEX38 (Crawley p. 149) de Hígados de rata en el ejemplo presentado originalmente en Sokal & Rohlf (1981). Te recuerdo que se trata de un experimento con un solo factor con tres tratamientos administrados a seis ratas, dos por tratamiento. El análisis se complica por el hecho de que, para el an?lisis, se tomaron tres muestras del hígado de cada rata y se hicieron dos determinaciones de contenido de glucógeno en cada muestra. Así, podríamos decir, un tanto derogativamente, que hay seis pseudoréplicas por rata para dar un total de 36 lecturas en total. Pero quizás en lugar de hablar en estos términos deberíamos simmplemente reconocer que lo que estamos haciendo es organizar un muestreao para obtener el dato de la variable de respuesta en el experimento, en lugar de hacer una “cosecha total”, que es la práctica ideal (pues evita introducir un fuente de “ruido” adicional).\n\n\nCódigo\nratas_g <- read.table(\"../experimentos-anidados/GLEX38.DAT\", col.names=\"glucogeno\")\n\nratas_g$tratamiento <- factor(rep(c(\"t1\",\"t2\",\"t3\"),each=12))\nratas_g$rata <- factor(rep(paste(\"r\", 1:6, sep=\"\"), each=6))\nratas_g$muestraH <- factor(rep(c(\"m1\", \"m2\", \"m3\"), times=6, each=2))\n\n\nLe doy estructura de grupos a la tabla\n\n\nCódigo\nratas_g <- groupedData(glucogeno ~  1 | ordered(rata) / muestraH,\n                       data = ratas_g,\n                       labels= list(x = \"rata\", y = \"contenido de glucógeno\" ),\n                       FUN = mean)\nstr(ratas_g)\n\n\nClasses 'nmGroupedData', 'groupedData' and 'data.frame':    36 obs. of  4 variables:\n $ glucogeno  : int  131 130 131 125 136 142 150 148 140 143 ...\n $ tratamiento: Factor w/ 3 levels \"t1\",\"t2\",\"t3\": 1 1 1 1 1 1 1 1 1 1 ...\n $ rata       : Factor w/ 6 levels \"r1\",\"r2\",\"r3\",..: 1 1 1 1 1 1 2 2 2 2 ...\n $ muestraH   : Factor w/ 3 levels \"m1\",\"m2\",\"m3\": 1 1 2 2 3 3 1 1 2 2 ...\n - attr(*, \"formula\")=Class 'formula'  language glucogeno ~ 1 | ordered(rata)/muestraH\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"formulaList\")=List of 2\n  ..$ ordered(rata):Class 'formula'  language ~ordered(rata)\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  ..$ muestraH     :Class 'formula'  language ~muestraH\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"rata\"\n  ..$ y: chr \"contenido de glucógeno\"\n - attr(*, \"order.groups\")=List of 2\n  ..$ ordered(rata): logi TRUE\n  ..$ muestraH     : logi TRUE\n - attr(*, \"FUN\")=function (x, ...)  \n\n\n\nExploración de los datos\nAprovechando las opciones de estructura de grupos puedo obtener resumenes exploratorios de manera muy simple.\n\n\nCódigo\ndata.frame(promedio = tapply (ratas_g$glucogeno, ratas_g$rata, function(x) round(mean(x), 2)))\n\n\n   promedio\nr1   132.50\nr2   148.50\nr3   149.67\nr4   152.33\nr5   134.33\nr6   136.00\n\n\nGraficación de los datos aprovechando la estructura agrupada que hemos adoptado.\n\n\nCódigo\nplot(ratas_g, inner =  ~ tratamiento, displayLeve=2)\n\n\n\n\n\n\n\nCódigo\nbwplot(glucogeno ~ tratamiento, boxmeans=T, data=ratas_g, \n     boxcol=14, xlab = \"Tratamiento\", ylab = \"Contenido de glucógeno\")\n\n\n\n\n\n\n\nModelación\nVeamos el enfoque con un modelo lineal de efectos mixtos.\n¿Cual es la estructura fija?, me puedes decir cuál es la ecuación correspondiente\nLa estructura aleatoria de los datos, cuando tiene varias fuentes, se representa como una lista de efectos (modelos) en la función lme() de la biblioteca nlme. Otra posibilidad es usar la biblioteca lme4 que contiene a la función lmer(). Al respecto, esta lectura puede ser de innterés\nEste caso, como ya vimmos, hay dos cosas en operación: 1. Hay una muestra aleatoria de ratas distintas en cada tratamiento. Cabe esperar un valor promedio de glucógeno distinto para cada animal. Esto lo representaré en el primer componente de la lista. 2. Hay una muestra aleatoria de fragmentos de hígado tomados de cada rata. Esperamos que estas muestras estimen una misma cantidad de glucógeno para cada animal. Esto lo representaré en el segundo componente de la lista.\nEn el código siguiente tanto el modelo “1” como el “2” son equivalente. Los presento como dos formas de plantear el modelo de efectos aleatorios. Hay que notar que no es correcto hacer comparaciones entre modelos que cambian en cuanto al componente “fijo” si el ajuste se hace mediante el método “REML”, en caso de tener hipótesis de interés en esta parte del modelo hay que emplear el método “ML”.\n\n\nCódigo\nratas.lme.m1 <- lme(fixed=glucogeno ~ tratamiento - 1, \n                    random=list(rata = ~ 1, muestraH= ~ 1),\n                    data=ratas_g)\nsummary(ratas.lme.m1)\n\n\nLinear mixed-effects model fit by REML\n  Data: ratas_g \n       AIC      BIC    logLik\n  231.6213 240.6003 -109.8106\n\nRandom effects:\n Formula: ~1 | rata\n        (Intercept)\nStdDev:    6.005399\n\n Formula: ~1 | muestraH %in% rata\n        (Intercept) Residual\nStdDev:    3.763863 4.600725\n\nFixed effects:  glucogeno ~ tratamiento - 1 \n                 Value Std.Error DF  t-value p-value\ntratamientot1 140.5000  4.707166  3 29.84811   1e-04\ntratamientot2 151.0000  4.707166  3 32.07875   1e-04\ntratamientot3 135.1667  4.707166  3 28.71509   1e-04\n Correlation: \n              trtmn1 trtmn2\ntratamientot2 0            \ntratamientot3 0      0     \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.48211987 -0.47263005  0.03061539  0.42934293  1.82934636 \n\nNumber of Observations: 36\nNumber of Groups: \n              rata muestraH %in% rata \n                 6                 18 \n\n\n\n\nCódigo\nratas.lme.m2 <- lme(fixed = glucogeno ~ tratamiento - 1, \n                    random = ~ 1 | rata / muestraH,\n                    data=ratas_g) \nsummary(ratas.lme.m2)\n\n\nLinear mixed-effects model fit by REML\n  Data: ratas_g \n       AIC      BIC    logLik\n  231.6213 240.6003 -109.8106\n\nRandom effects:\n Formula: ~1 | rata\n        (Intercept)\nStdDev:    6.005399\n\n Formula: ~1 | muestraH %in% rata\n        (Intercept) Residual\nStdDev:    3.763863 4.600725\n\nFixed effects:  glucogeno ~ tratamiento - 1 \n                 Value Std.Error DF  t-value p-value\ntratamientot1 140.5000  4.707166  3 29.84811   1e-04\ntratamientot2 151.0000  4.707166  3 32.07875   1e-04\ntratamientot3 135.1667  4.707166  3 28.71509   1e-04\n Correlation: \n              trtmn1 trtmn2\ntratamientot2 0            \ntratamientot3 0      0     \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.48211987 -0.47263005  0.03061539  0.42934293  1.82934636 \n\nNumber of Observations: 36\nNumber of Groups: \n              rata muestraH %in% rata \n                 6                 18 \n\n\nPara comparar el efecto del tratamiento hay que usar el método “ML” y ajustar los modelos que contrastan la hipótesis de interés en el componente fijo.\nModelo “nulo” en cuanto a efectos fijos\n\n\nCódigo\nstr(ratas_g)\n\n\nClasses 'nmGroupedData', 'groupedData' and 'data.frame':    36 obs. of  4 variables:\n $ glucogeno  : int  131 130 131 125 136 142 150 148 140 143 ...\n $ tratamiento: Factor w/ 3 levels \"t1\",\"t2\",\"t3\": 1 1 1 1 1 1 1 1 1 1 ...\n $ rata       : Factor w/ 6 levels \"r1\",\"r2\",\"r3\",..: 1 1 1 1 1 1 2 2 2 2 ...\n $ muestraH   : Factor w/ 3 levels \"m1\",\"m2\",\"m3\": 1 1 2 2 3 3 1 1 2 2 ...\n - attr(*, \"formula\")=Class 'formula'  language glucogeno ~ 1 | ordered(rata)/muestraH\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"formulaList\")=List of 2\n  ..$ ordered(rata):Class 'formula'  language ~ordered(rata)\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  ..$ muestraH     :Class 'formula'  language ~muestraH\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"rata\"\n  ..$ y: chr \"contenido de glucógeno\"\n - attr(*, \"order.groups\")=List of 2\n  ..$ ordered(rata): logi TRUE\n  ..$ muestraH     : logi TRUE\n - attr(*, \"FUN\")=function (x, ...)  \n\n\n\n\nCódigo\nratas.lme.m3 <- lme(fixed=glucogeno ~ 1, data=ratas_g, \n                    random=~1|rata/muestraH, method=\"ML\") \nratas.lme.m3\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: ratas_g \n  Log-likelihood: -119.8834\n  Fixed: glucogeno ~ 1 \n(Intercept) \n   142.2222 \n\nRandom effects:\n Formula: ~1 | rata\n        (Intercept)\nStdDev:    7.561272\n\n Formula: ~1 | muestraH %in% rata\n        (Intercept) Residual\nStdDev:    3.763863 4.600725\n\nNumber of Observations: 36\nNumber of Groups: \n              rata muestraH %in% rata \n                 6                 18 \n\n\nModelo “completo”\n\n\nCódigo\nratas.lme.m4 <- lme(fixed=glucogeno ~ tratamiento, data=ratas_g, \n                random=~1|rata/muestraH, method=\"ML\") \nratas.lme.m4\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: ratas_g \n  Log-likelihood: -116.6353\n  Fixed: glucogeno ~ tratamiento \n  (Intercept) tratamientot2 tratamientot3 \n   140.500000     10.500000     -5.333333 \n\nRandom effects:\n Formula: ~1 | rata\n        (Intercept)\nStdDev:     3.72915\n\n Formula: ~1 | muestraH %in% rata\n        (Intercept) Residual\nStdDev:    3.763793 4.600775\n\nNumber of Observations: 36\nNumber of Groups: \n              rata muestraH %in% rata \n                 6                 18 \n\n\nAsí podemos comparar el análisis con modelos mixtos y el convencional en cuanto al efecto del tratamiento.\n\n\nCódigo\nanova(ratas.lme.m4, ratas.lme.m3)\n\n\n             Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4     1  6 245.2705 254.7716 -116.6353                        \nratas.lme.m3     2  4 247.7667 254.1008 -119.8834 1 vs 2 6.496197  0.0388\n\n\n\n\nCódigo\nratas.completo.lm <- lm(glucogeno~tratamiento/rata/muestraH, data=ratas_g)\nanova(ratas.completo.lm)\n\n\nAnalysis of Variance Table\n\nResponse: glucogeno\n                          Df  Sum Sq Mean Sq F value    Pr(>F)    \ntratamiento                2 1557.56  778.78 36.7927 4.375e-07 ***\ntratamiento:rata           3  797.67  265.89 12.5617 0.0001143 ***\ntratamiento:rata:muestraH 12  594.00   49.50  2.3386 0.0502907 .  \nResiduals                 18  381.00   21.17                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nIntervalos de confianza\nEs importante contar con intervalos de confianza para describir de mmejor manera los resultados obtenidos. La forma de hacerlo para cada tipo de modelo pude varia, así que ilustraré un par de rutas para obtenerlos."
  },
  {
    "objectID": "posts/modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "href": "posts/modelos-mixtos/index.html#modelo-de-efectos-mixtos-lme",
    "title": "Modelos de Efectos Mixtos",
    "section": "Modelo de efectos mixtos: lme",
    "text": "Modelo de efectos mixtos: lme\n\n\nCódigo\nratas.lme4.ic <- predict(ratas.lme.m4, level = 0, type = \"predict\")\n\n\n\n\nCódigo\nratas.lme4.ic  <- data.frame(ajustado=as.numeric(ratas.lme4.ic), tratamiento=ratas_g$tratamiento)\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507296 140.500000 147.492704\ntratamientot2  -4.479982  10.500000  25.479982\ntratamientot3 -20.313315  -5.333333   9.646648\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\n\nModelo de regresión convencional: lm\n\n\nCódigo\nratas.lm.ic <- as.data.frame(predict(ratas.completo.lm, interval = 'confidence',\n                                     conf.level=0.95, ci.fit=TRUE))\n\n\n\n\nCódigo\nratas.lm.ic$tratamiento <- ratas_g$tratamiento\n\n\n\n\nCódigo\ndata.frame(min=tapply(ratas.lm.ic$lwr, ratas.lm.ic$tratamiento, mean),\n           media=tapply(ratas.lm.ic$fit, ratas.lm.ic$tratamiento, mean),\n           max=tapply(ratas.lm.ic$upr, ratas.lm.ic$tratamiento, mean))\n\n\n        min    media      max\nt1 133.6653 140.5000 147.3347\nt2 144.1653 151.0000 157.8347\nt3 128.3319 135.1667 142.0014\n\n\nBueno, veamos los residuos!!!\n\n\nCódigo\nplot(ratas.lme.m4, rata ~ resid(.) | tratamiento, xlab=\"residuos\")\n\n\n\n\n\n\n\nCódigo\nplot(ratas.lme.m4)\n\n\n\n\n\n\n\nComparaciones múltiples\nVeamos qué está pasando con los efectos de los tratamientos una vez que hemos resuelto con la prueba omnibus que hay algún efecto de tratamiento.\nEl modelo completo, ¿cambia significativamente al recodifcar los tratamientos de manera que supongamos que el t1 no difiere del t2? Esto equivale a comparar los dos mmodelos respectivos.\n\n\nCódigo\nlibrary(tidyverse, warn.conflicts = FALSE)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   1.0.0      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::collapse() masks nlme::collapse()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n\n\nCódigo\nratas_g$trat_v1 <-recode_factor(ratas_g$tratamiento, \"t2\"=\"t1\")\nratas.lme.m4A <- lme(fixed=glucogeno ~ trat_v1, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \n\nratas_g$trat_v2 <-recode_factor(ratas_g$tratamiento, \"t3\"=\"t2\")\nratas.lme.m4B <- lme(fixed=glucogeno ~ trat_v2, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \n\nratas_g$trat_v3 <-recode_factor(ratas_g$tratamiento, \"t3\"=\"t1\")\nratas.lme.m4C <- lme(fixed=glucogeno ~ trat_v3, data=ratas_g, \n                     random=~1|rata/muestraH, method=\"ML\") \nhead(ratas_g)\n\n\nGrouped Data: glucogeno ~ 1 | ordered(rata)/muestraH\n  glucogeno tratamiento rata muestraH trat_v1 trat_v2 trat_v3\n1       131          t1   r1       m1      t1      t1      t1\n2       130          t1   r1       m1      t1      t1      t1\n3       131          t1   r1       m2      t1      t1      t1\n4       125          t1   r1       m2      t1      t1      t1\n5       136          t1   r1       m3      t1      t1      t1\n6       142          t1   r1       m3      t1      t1      t1\n\n\n¿Qué sugieren estos resultados estadísticos?\n\n\nCódigo\nanova(ratas.lme.m4A, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nratas.lme.m4A     1  5 246.8941 254.8117 -118.4471                       \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 3.62358   0.057\n\n\nPreguntemonos lo mismo respecto de los tratamientos t2 y t3. Veamos lo que resulta al comparar los modelos\n\n\nCódigo\nanova(ratas.lme.m4B, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4B     1  5 249.6292 257.5467 -119.8146                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 6.358622  0.0117\n\n\nAhora los tratamientos t1 y t3. ¿qué resulta al comparar los modelos?\n\n\nCódigo\nanova(ratas.lme.m4C, ratas.lme.m4)\n\n\n              Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nratas.lme.m4C     1  5 244.4339 252.3514 -117.2169                        \nratas.lme.m4      2  6 245.2705 254.7716 -116.6353 1 vs 2 1.163313  0.2808\n\n\n¿Qué decisión tomarás?\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.315  <.0001\ntrat_v3         1     4    8.116  0.0464\n\n\n\n\nCódigo\nintervals(ratas.lme.m4)$fixed\n\n\n                   lower       est.      upper\n(Intercept)   133.507296 140.500000 147.492704\ntratamientot2  -4.479982  10.500000  25.479982\ntratamientot3 -20.313315  -5.333333   9.646648\nattr(,\"label\")\n[1] \"Fixed effects:\"\n\n\nQuizás es más interesante ver los resultados en términos de los valores estimados para cada tratamiento, en lugar de sobre sus diferencias.\n\n\nCódigo\nt(data.frame(trat_1 = intervals(ratas.lme.m4)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4)$fixed[1:2,]),\n             trat_3 = colSums(intervals(ratas.lme.m4)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 133.5073 140.5000 147.4927\ntrat_2 129.0273 151.0000 172.9727\ntrat_3 108.7140 145.6667 182.6193\n\n\nSi optaramos por tomar al modelo C como nuestro modelo mínimo adecuado para describir el experimento de glucógeno, los resultados se verían así:\n\n\nCódigo\nanova(ratas.lme.m4C)\n\n\n            numDF denDF  F-value p-value\n(Intercept)     1    18 4261.315  <.0001\ntrat_v3         1     4    8.116  0.0464\n\n\nEste modelo sugiere que es posible argumentar que el tratamiento combinando t1 y t3 difiere en forma apreciable o significativa con respecto del t2. Esto se aprecia al considerar los valores promedio de los tratamientos, pero no es realmente muy evidente. La forma como estoy calculando los valores tiene que considerar el tipo de reparametrización y la configuración del modelo, no olvides eso.\n\n\nCódigo\nnivel_confianza <- 0.90\nt(data.frame(trat_1 = intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:2,]),\n                 trat_3 = colSums(intervals(ratas.lme.m4, level = nivel_confianza)$fixed[1:3,])))\n\n\n          lower     est.    upper\ntrat_1 134.7283 140.5000 146.2717\ntrat_2 134.1509 151.0000 167.8491\ntrat_3 117.7401 145.6667 173.5932\n\n\n\n\nCódigo\nt(data.frame(trat_1_y_3 = intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1,],\n             trat_2 = colSums(intervals(ratas.lme.m4C, level = nivel_confianza)$fixed[1:2,])))\n\n\n              lower     est.    upper\ntrat_1_y_3 133.3366 137.8333 142.3300\ntrat_2     136.9281 151.0000 165.0719"
  },
  {
    "objectID": "posts/restringir-aleatorizacion/index.html#manos",
    "href": "posts/restringir-aleatorizacion/index.html#manos",
    "title": "Restricciones a la aleatorización",
    "section": "Manos",
    "text": "Manos\nConsidera que estamos midiendo la mano izquierda y la derecha de varios individuos, las medidas están emparejadas dentro de cada individuo. Es decir, queremos controlar estadísticamente las diferencias entre individuos, así nos aseguramos que la mano izquierda del individuo A sea analizada en conjunto con la mano derecha del individuo A, ya que suponemos que alguien con una mano izquierda grande tendrá una mano derecha grande. Por lo tanto, la variable Individuo se incluirá en el modelo como una variable aleatoria. Se podría pensar que cada Individuo representa un bloque que incluye una medida para la mano izquierda y una medida para la mano derecha.\n\n\nCódigo\nmanos <- read.table(\"manos.dat\", sep = \",\", header = T, stringsAsFactors = T)\nhead(manos)\n\n\n  Individual Hand Length\n1          A Left   17.5\n2          B Left   18.4\n3          C Left   16.2\n4          D Left   14.5\n5          E Left   13.5\n6          F Left   18.9\n\n\n\nInspección de los datos\n\n\nCódigo\ntapply(manos$Length, list(manos$Hand, manos$Individual), mean)\n\n\n         A    B    C    D    E    F    G    H    I    J    K    L    M    N\nLeft  17.5 18.4 16.2 14.5 13.5 18.9 19.5 21.1 17.8 16.8 18.4 17.3 18.9 16.4\nRight 17.6 18.5 15.9 14.9 13.7 18.9 19.5 21.5 18.5 17.1 18.9 17.5 19.5 16.5\n         O    P\nLeft  17.5 15.0\nRight 17.4 15.6\n\n\n\n\nCódigo\ninteraction.plot(manos$Individual,manos$Hand, manos$Length)\n\n\n\n\n\n\n\nCódigo\nmanos_modelo_1 <- lm(Length ~ 1, data = manos)\nsummary(manos_modelo_1)\n\n\n\nCall:\nlm(formula = Length ~ 1, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.975 -1.125  0.025  1.425  4.025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.4750     0.3415   51.16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.932 on 31 degrees of freedom\n\n\n\n\nCódigo\nmanos_modelo_2 <- lm(Length ~ Hand, data = manos)\nsummary(manos_modelo_2)\n\n\n\nCall:\nlm(formula = Length ~ Hand, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.894 -1.109  0.075  1.306  3.906 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.3562     0.4900  35.418   <2e-16 ***\nHandRight     0.2375     0.6930   0.343    0.734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 30 degrees of freedom\nMultiple R-squared:  0.003899,  Adjusted R-squared:  -0.0293 \nF-statistic: 0.1174 on 1 and 30 DF,  p-value: 0.7342\n\n\n\n\nCódigo\nmanos_modelo_3 <- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_3)\n\n\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.43125    0.14440 120.714  < 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,    Adjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n\n\n\n\nCódigo\nanova(manos_modelo_3)\n\n\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(>F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEs cierto que el efecto de individuo queda raro en este modelo, pes nos lo reporta en estimadores que tienen sentido como si se tratara de un factor de efectos fijos, es decir que nos interesa decir algo específico sobre esos individuos y ningún otro. Esto obviamente nos es así. El factor individuo es de efectos aleatorios, simplemente que lm` no prevé esta situación. Los resultados apuntan en la dirección correcta y los valores del factor Hand son válidos. Lo podemos manejar razonablemente simplemente recordando que el individuo es de efectos aleatorios y que por tanto no tienen mucho sentido, generalmente, hacer referencia a los estimadores puntuales que produce la regresión. Lo que sí tiene interés es la estimación de las varianzas, que permite así corregir e idealmente lograr mayor precisión en la estimación en los tratamientos de interés. En este caso habría que notar que la varianza estimada en el residuo da cuenta tanto de la variación aleatoria que tenemos al medir las unidades experimentales como la del error de restricción asociado con las peculiaridades de, en este caso, cada persona que se midió: \\(\\sigma^{2} + t \\sigma^{2}_{\\delta}\\) . La medición de esta varianza combinada, persona + sus peculiaridades = 7.6453, sugiere que es buena idea controlar su efecto. En esto mismos términos la varianza del factor hand es \\(\\sigma + t\\sigma\\^{2}_{\\delta} + r\\sigma^{2}_{H}\\), lo qe hace válido probar el efecto fijo de hand.\n\\[\nF = \\frac {Mean Sq Hand} {Mn Sq error} = \\frac {0.4513}{0.0392} = 11.497\n\\] con 1 y 15 grados de libertad. En R tenemos acceso a la distribbución de F con la función qfque calcula la probabilidad acumulada entre el dato q que le doy, así como los grados de libertad asociados.\n\n\nCódigo\nvarianza <- anova(manos_modelo_3)\n\npf(q = varianza$`F value`[1], df1 = 1, df2 = 15, lower.tail = FALSE)\n\n\n[1] 0.004034071\n\n\nAunque la forma como analizamos estos datos no es la ideal para el caso, podemos ver que produce resultados perfectamente adecuados para la variable de interés, siempre y cuando seamos cocientes de que la función usada aquí en R, no maneja apropiadamente los factores de efectos aleatorios y por lo tanto no debemos hacer mayores interpretaciones de los términos correspondientes a esos factores."
  },
  {
    "objectID": "posts/restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "href": "posts/restringir-aleatorizacion/index.html#qué-tanto-tiempo-puede-correr-un-experimento",
    "title": "Restricciones a la aleatorización",
    "section": "Qué tanto tiempo puede “correr” un experimento",
    "text": "Qué tanto tiempo puede “correr” un experimento\nCuando Fisher concibió hacer experimentos en la estación experimental de Rothamsted en Inglaterra, recurriendo al auxilio del enfoque estadístico que él y otros investigadores de la época idearon, pensaban a largo plazo. Encontré este documento que podría ser de su interés. La estación experimental tiene disponiible los datos de estos experimentos. Por ejemplo Este “dataset” son los rendimientos anuales de trigo de “parcelas selectas” del experimento de trigo que aún hoy corren en Broadbalk . La serie tiene los datos de 1852-1918, tal y como los usó R.A. Fisher para su artículo de 1921 ‘Studies in crop variation’."
  }
]