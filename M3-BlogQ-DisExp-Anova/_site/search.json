[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca del módulo III",
    "section": "",
    "text": "El módulo III se ocupa de las nociones básicas de diseño de experimentos y las técnicas estadísticas utilizadas para analizarlos: El Análisis de Varianza (Andeva o Anova).\nSe reúnen aquí los documentos y código en R utilizados como apoyo audiovisual en clase."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M3 - Diseño de Experimentos",
    "section": "",
    "text": "Uso básico de R\n\n\n\n\n\n\n\nnoticias\n\n\nclase\n\n\ntarea\n\n\n\n\n\n\n\n\n\n\n\n24 ene 2023\n\n\nMiguel Equihua\n\n\n\n\n\n\n  \n\n\n\n\nClase 2 - Vampiros y ciencia\n\n\n\n\n\n\n\nclase\n\n\n\n\n\n\n\n\n\n\n\n21 ene 2023\n\n\nMiguel Equihua\n\n\n\n\n\n\n  \n\n\n\n\nBienvenidos al Módulo III de estadística\n\n\n\n\n\n\n\nnoticias\n\n\n\n\n\n\n\n\n\n\n\n21 ene 2023\n\n\nMiguel Equihua\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Uso básico de R",
    "section": "",
    "text": "Este es un post con código ejecutable\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "posts/Vampiros-y-ciencia/index.html",
    "href": "posts/Vampiros-y-ciencia/index.html",
    "title": "Clase 2 - Vampiros y ciencia",
    "section": "",
    "text": "McElreath (2020) presenta en este libro el hipotético ejemplo de la prueba de sangre para vampirismo. Propone que hay un análisis de sangre que detecta correctamente 95% de las veces, la afiliación de un individuo al linage de los inmortales vampiros. En notación matemática:\n\\[\n{Pr(resultado~ positivo~de~la~prueba|vampiro) = 0.95}\n\\]\nEs una prueba muy precisa, casi siempre identificando vampiros reales. Sin embargo, también comete errores y produce falsos positivos. Es así que el uno por ciento de las veces diagnostica incorrectamente a los simples mortales como vampiros:\n\\[\n{Pr(resultado~positivo~de~la~prueba|mortal) = 0.01}\n\\]\nLa última pieza de información que necesitamos es saber que los vampiros en realidad son bastante raros. Sólo el 0.1% de la población lo es, lo que implica:\n\\[\n{Pr(vampiro) = 0.001}\n\\]\nA partir de este conocimiento científico, supongamos que un amigo da positivo en el test de vampirismo.\n¿Cuál es la probabilidad de que sea un inmortal chupasangre?\nEl enfoque de investigación formal empezaría por usar el teorema de Bayes para deducir la probabilidad \\({Pr(vampiro|positivo)}\\), lo que en cierta forma implica “invertir la probabilidad”, pues lo que ahora sabemos es el valor de \\({Pr(positivo|vampiro)}\\). El cálculo puede presentarse como:\n\\[\n\\Pr(vampiro|positivo) = \\frac{Pr(positivo|vampiro) \\times Pr(vampiro)}{Pr(positivo)}\n\\]\nen donde \\({Pr(positivo)}\\) es la probabilidad promedio de los resultados positivos de la prueba, es decir,\n\\[\nPr(positivo) = Pr(positivo|vampiro)\\times Pr(vampiro) + Pr(positivo|mortal) \\times ({1 − Pr(vampiro)})\n\\]\nTodo esto lo podemos hacer en R.\nPrimero tomamos nota de lo que ya sabemos al principio, ¡a priori!\n\nPr_positivo_vampiro <- 0.95 \nPr_positivo_Mortal <- 0.01 \nPr_vampiro <- 0.001 \n\nTomamos la fórmula de Bayes para invertir la probabilidad, pues queremos saber qué está pasando cuando tenemos la fortuna de toparnos con un resultado positivo en la prueba de sangre: \\(Pr(positivo|vampiro)\\) Esto equivale a preguntarnos, ya vimos el resultado científico que significa la prueba de sangre, entonce ¿será vampiro el que dió esa muestra?:\n\\[Pr(vampiro|positivo)\\]\n\nPr_positivo <- Pr_positivo_vampiro * Pr_vampiro + Pr_positivo_Mortal * (1 - Pr_vampiro) \n\nPr_vampiro_positivo <- (Pr_positivo_vampiro * Pr_vampiro) / Pr_positivo\n\nround(Pr_vampiro_positivo, 3)\n\n[1] 0.087\n\n\nPor lo tanto, la probabilidad de que el amigo sea en realidad un vampiro es 8.7%.\n¿Encuentras este resultado afin o contrario a lo que pensabas antes de hacer los cálculos?\nEste es un resultado muy importante. Exactamente así, o algo muy parecido, es el proccedimiento que se sigue en muchos contextos de prueba realistas: * las pruebas de PCR, antígeno o anticuerpos para SarsCov-2 * la prueba del VIH * la del DNA en un perfil criminal * la prueba de significancia estadística.\nQuizás ayude a mejorar la intuición que tenemos de las cosas el considerar que siempre que la condición de interés sea muy rara, desarrollar una prueba excelente capaz de diagnosticar bien todos los casos verdaderos (aunque inveitablemente produzca también algunos falsos positivos), seguiría sin ser garantía de que un resultado positivo en general conlleve mucha información.\nLa razón es que usualmente resulta inevitable tener falsos positivos y por simple aritmética, esos casos serán la mayoría de los resultados que tendremos, incluso si todos los verdaderos positivos fueran detectados correctamente.\nAunque, como dice McElreath, no hay nada particularmente bayesiano aqui. Podríamos pensar que la ecuación que usamos aquí salio de la nada, aunque quizás la recuerdes de algún curso previo, de alguna charla interesante por ahí o incluso de lo que viste con Rosario ¡hace unas semanas!\nQuizás el ejemplo puede verse en forma más intuitiva utilizando otra narrativa para comprender lo que está ocurriendo. Digamos que en lugar de informar sobre las probabilidades, como antes, te digo lo siguiente:\n\nEn una población de 100,000 personas, 100 de ellas son vampiros.\nDe los 100 que son vampiros 95 darán positivo en la prueba de vampirismo.\nDe los 99,900 simples mortales, 999 darán positivo a la prueba de vampirismo.\n\nAhora piensa en esto, si hacemos pruebas a las 100,000 personas, ¿qué proporción de los que dan positivo en las pruebas de vampirismo son realmente vampiros?\nMuchas personas, aunque ciertamente no todas, encuentran esta forma de contar la historia mucho más fácil. Sigamos por este camino.\n¿Qué tal si contamos el número de personas que dan positivo?: 95 + 999 = 1094. De estas 1094 pruebas positivas, 95 de ellas son vampiros reales, lo que nos lleva sencillamente a esto:\n\\[\nPr(vampiro|positivo) = \\frac{95}{1094} ≈ 0.087\n\\]\nEsta es exatamente la misma respuesta de 8.7% que encontramos antes. Pero no tuvimos que recordar la ´“formula mágica” de Bayes, nada más tuvimos que contar y pensar con calma.\nEsta forma de presentar el problema mediante el “conteo de los actores” en lugar de recurrir a probabilidades, suele denominarse formato de frecuencia o frecuencias naturales.\nLas razones propuestas para explicar el por qué el formato de frecuencia ayuda a la gente a intuir el enfoque correcto siguen siendo polémicas. Podría ser que de entrada sólo podemos encontrarnos con conteos en el mundo real.\nQuizás sea cierto que nadie ha visto nunca una probabilidad andando por ahí. Independientemente de la explicación de este fenómeno, podemos explotarlo.\nLos eventos muestreados en el análisis de las distribuciones de probabilidades de modelos estadísticos en algún análisis de datos, son los valores de los parámetros.\nLa mayoría de los parámetros no tienen una “materialización” empírica exacta.\nEl formalismo bayesiano trata las distribuciones de los parámetros como una plausibilidad relativa, no como un proceso aleatorio que ocurre en el mundo físico. En cualquier caso, la aleatoriedad es siempre una propiedad de la información, nunca del mundo real.\n\n\n¿Podemos confiar en que la estadística nos proteja de la mala ciencia?.\nEl ejemplo del vampirismo que acabamos de ver tiene la misma estructura lógica que muchos problemas de detección considerando que:\n\nHay algún estado binario al que no tenemos acceso.\nObservamos un indicio imperfecto del estado oculto.\n(Deberíamos/podríamos) usar el teorema de Bayes para deducir lógicamente el impacto del indicio en nuestra incertidumbre (aunque ve lo que salió en el periódico)\n\nLa inferencia científica puede enmarcase en términos similares:\n\nUna hipótesis es verdadera o falsa, pero no podemos saberlo;\nObtenemos un indicio estadístico de la falsedad de la hipótesis;\nDebemos/podemos utilizar el teorema de Bayes para deducir lógicamente el impacto del indicio en el estado de la hipótesis.\n\nEs el tercer paso el que casi nunca se hace. Sin debatir por lo pronto si debemos o no usar a Bayes, consideremos por un momento la idea como un ejemplo de juguete.\n\n\n\n\nSupongamos que la probabilidad de obtener un hallazgo positivo, cuando la hipótesis postulada es cierta, es \\({Pr(señal~detectada|verdadero) =Pr(H|V) = 0.95}\\).\nEse es lo que se suele llamar la potencia de la prueba.\n\n\n\nSupongamos que la probabilidad de un hallazgo positivo, cuando una hipótesis es falsa, es \\({Pr(señal~detectada|falso) = Pr(H|F) = 0.05}\\).\nEsa es la tasa de falsos positivos, se trata del, digamos 5%, de la prueba de significancia convencional.\n\n\n\nFinalmente, tenemos que establecer la tasa base con la que ocurren las hipótesis que son verdaderas. Supongamos, por ejemplo, que 1 de cada 100 hipótesis resulta ser verdadera. Entonces \\({Pr(verdadero) = P(V) = 0.01}\\).\nEn realidad nadie conoce este valor ni se ve posible conocerlo, pero la historia de la ciencia sugiere que es pequeño.\n\n\n\nPara averiguar esto, calculamos la componente a posteriori:\n\\[\nPr(detectada|Hipótesis) = \\frac{Pr(Hipótesis|detectada) Pr(detectado)} {Pr(Hipótesis)} = \\\\\n\\\\\n\\frac{Pr(H|V) Pr(V)} {Pr(H|V) Pr(V) + Pr(H|F) Pr(F)}\n\\\\\n\\]\n\nPr_posterior_hallazgo_verdadero <- (0.95 * 0.01) / ((0.95 * 0.01) + (0.05 * (1-0.01)))\nPr_posterior_hallazgo_verdadero\n\n[1] 0.1610169\n\n\nComo podemos ver, al substituir los valores imaginados, encontramos que la respuesta es aproximadamente \\({Pr(V|H) = 0.16}\\).\nAsí que un resultado positivo corresponde a un 16% de probabilidad de que la hipótesis sea cierta.\nEste es el mismo fenómeno de baja tasa de base que se aplica en las pruebas médicas (y en nuestro ejemplo de vampiros).\nPuedes reducir la tasa de falsos positivos al 1% y ¿qué pasaría?\n\n\n\n\nUna manera de explorar esto es haciendo un escript, algorítmo o programa que nos permita automatizar una tarea repetitiva y potencialmente aburrida. Veamos como hacerlo.\n\nciencia <- function (pr_pos_verdadero = 0.95, pr_verdadero = 0.01)\n{\n    pr_falso <- 1 - pr_verdadero\n    pr_pos_falso <- 1 - pr_pos_verdadero\n\n    pr_verdadero_pos <- pr_pos_verdadero * pr_verdadero / (pr_pos_verdadero * pr_verdadero + pr_pos_falso*pr_falso)\n\n    return(pr_verdadero_pos)\n}\n\nHemos definido un programa como una función en R. Esta función puede tomar datos y procesarlos de acuerdo con la lógica que le hemos especificado.\nAhora podemos experimentar para tener una idea aproximada de lo que está pasando.\n\n# Elegimos una serie de valores de interés\nvalores_de_interés <- seq(0.9, 0.99, 0.01)\n\n# Creamos un espacio de memoria vacío para anotar ahí los cálculos\nresultados <- data.frame(numeric(0), numeric(0))\nfor (pr in valores_de_interés) \n    resultados <- rbind(resultados, c(pr, ciencia(pr, 0.01)))\n\nnames(resultados) <- c(\"p_error\", \"p_post\")\n\nAhora podemos ver los resultados del experimento con ayuda de una gráfica.\n\n# Área de graficación. mar() para el margen. oma() alrededor del margen.\npar(oma=c(2,3,1,2)) # abajo=2, izq=3, arriba=1, der=2\npar(mar=c(4,4,2,2) + 0.7)\n\n# Tamaño de la gráfica\noptions(repr.plot.width = 15, repr.plot.height = 5)\n\n# Gráfica\nplot(x = 1 - resultados$p_error, y = resultados$p_post,\n     type = \"b\", xlab = \"valor de P\", ylab = \"Pr post detección positiva\", cex = 2, \n     cex.axis  = 2, cex.lab = 2)\n\n\n\n\n\n\n\nUna investigación muy exigente que reduce la detección de falsos positivos a 1%, nos permite llevar la probabilidad posterior de descubrimientos exitosos hasta 0.5.\nApenas tan buena como el lanzamiento de una moneda.\n¿A dónde nos lleva este razonamiento de juguete?.\nQuizás nos sugiera que lo más importante es mejorar la tasa base, \\({Pr(V)}\\), y eso requiere pensar mejor, no hacer muchas más pruebas o incluso ponerse exageradamente exigente. ¿Tú que piensas?\n\n\n\n\nEl planteamiento de la prueba de significancia estadística de hipótesis se pueden encontrar ya en el siglo XIX, su formalización teórica realmente ocurre en los años 20 y 30 del siglo XX con las publicaciones de Sir Ronald Fisher, Jerzy Neyman y Egon Pearson.\nEntre estos autores existieron diferencias filosóficas y conceptuales entre sus planteamientos y concepciones. En special Fisher y Neyman sostuvieron acres debates que sólo interrumpieron con el fallecimiento de Fisher en 1962. No obstante el debate continua hasta hoy.\nEl resultado es que el uso actual de la prueba estadística de hipótesis se ha conformado como un extraño híbrido surgido de una mezcla más o menos ecléctica de las dos corrientes y no tanto una teoría coherente sobre la prueba de hipótesis.\n\n\nEl objetivo de una prueba de significancia es hacer inferencias sobre un parámetro que el investigador concibe asociado a un atributo numérico relevante de la población que define su objetivo de investigación. El procedimiento utiliza como base los datos de una muestra extraída de esa población. El enfoque se opera específicamente como un instrumento para excluir un valor o un rango de valores específicos como plausibles para el parámetro.\n\n\n\nConstruir un modelo estadístico. Se trata de un conjunto de supuestos sobre las variables de interés.\nEspecificar la hipótesis nula.\nDefinir un estadístico de contraste (frecuentemente llamada “la prueba estadística”).\nIdentificar la distribución del estadístico de contraste bajo los supuestos del modelo.\nCalcular, bajo el supuesto de la hipótesis nula, el valor del estadístico de contraste en la muestra observada.\nCalcular la probabilidad de tener un valor del estadístico como el resultante o un valor más extremo en la distribución de referencia (el famosos valor p).\nAceptar o rechazar la hipótesis nula. Si el valor p es menor que el criterio α de significancia (especificado a priori), se rechaza la hipótesis nula, en el caso contrario se acepta o por lo menos no se rechaza (por lo pronto).\n\nRechazar la hipótesis nula es algo que quizás produce poca tensión emosional, quizás hasta un alivio, finalmente, el investigador sospecha (desea mostrar) que lo interesante está en otra parte, en su juego de hipótesis alternativas.\n¿Es este procedimiento afin al refutacionismo Popperiano?.\nPara interpretar correctamente un valor p se necesita tener claro que se opera dentro de una marco conceptual frecuentista. Esto lleva a que se conciba a los parámetros del modelo estadístico como constantes en la población objetivo (valor fijo que nunca se conoce en realidad).\nAdemás se asume que, al menos conceptualmente, sería posible repetir el experimento un número infinito de veces. También se asume que siempre se está muestreando la misma población objetivo (universo muestral) así que los parámetros tienen el mismo valor, pero las muestras fluctúan aleatoriamente.\nBajo estos supuestos es aceptable considerar que el estadístico de prueba se distribuye de acuerdo con el modelo de probabilidades propuesto para construir el el contraste y por lo tanto da cuenta de las variaciones esperadas entre las diferentes repeticiones del experimento.\nEn la aproximación tradicional a la contrastación estadística de hipótesis (frecuentista) se parte de la formulación de proposiciones hipotéticas que son descritas con referencia a alguna distribución de probabilidades.\nUn componente es la llamada hipótesis nula (\\(H_{0}\\)).\nSe concibe como un planteamiento que asume la ausencia de efecto de los “factores explicativos”.\nEn contraste se propone una o más hipótesis alternativas (\\(H_{1...n}\\)), en las que se valora algún o algunos efectos de los “factores explicativos”. La propocisión hipotética que hacemos se traduce en valores que podemos comparar con un conjunto de valores a los que consideramos observados. La diferencia entre estos dos conjuntos de valores nos permiten valorar la factibilidad de nuestra proposición.\n\nEn la práctica, suele ocurrir que se concentre la atención en la hipótesis nula expresada con la gran simplicidad que implica la ausencia de efectos y se proceda con menor rigurosidad el análisis de la hipótesis alternativa, la que suele procesarse en forma más bien exploratoria mediante procedimientos de comparaciones múltiples.\n\n\n\n\nVeamos este caso: Si en 15 manos de póquer en una noche, al mismo jugador le salen 4 ases.\n\n\n\n\njugador\nSuerte en la noche\n\n\n\n\nJugador 1\n2 veces 4 ases\n\n\nJugador 2\n5 veces 4 ases\n\n\nJugador 3\n12 veces 4 ases\n\n\n\n¿Explica como aplicarías el enfoque centrado en hipótesis nula? * \\(H_{0}\\) = el jugador no es tramposo * \\(H_{a1}\\) = el jugador es tramposo * \\(H_{a2}\\) = el jugador es un mago\n¿Qué piensas de cada jugador?\nSi quieres jugar con este ejemplo y hacer un poco de probabilidades con R te sugiero instalar la biblioteca RcppAlgos.\n\nConsidera que el número total de manos es el número de combinaciones posibles de las cartas en el mazo, usa la función comboCount() para contarlas.\nLuego hay que considerar que el valor de la carta que se va a repetir la podemos escoger de 13 maneras distintas y las cuatros cartas con este valor las podemos escoger de una sola manera.\nPara la carta que no forma parte del póker hay 12 valores posibles y una vez escogido el valor\nhay 4 posibles maneras de escoger las carta y así suscesivamente.\n\nprobabilidades en el póker\nLas probabilidades de interés en esta Noche de póker empiezan con averiguar ¿cuántas manos distintas se podrán tener a partir de un mazo normal de 52 cartas y entregando 5 naipes a cada jugador.\n\n# Para funciones sobre combinaciones utilizo esta librería\nlibrary(RcppAlgos)\n\n# combinaciones que incluyen una mano póker. Cualquiera combinaciones de cuatro cartas iguales \n# más alguna carta cualquiera de las restantes (1 de entre 48). Hay 13 posibilidades de hacer póker\n# poner \\n significa agregar un salto de renglón en donde se anote.\n# total de arreglos posibles de cinco cartas\nn_total_de_manos <- comboCount(52, 5)  \ncat(\"Número total de manos, arreglos de 5 cartas, posibles: \", n_total_de_manos, \"\\n\")\n\nNúmero total de manos, arreglos de 5 cartas, posibles:  2598960 \n\n\n¿Qué tan probable es conseguir un póker?\n\n# Arreglos que resutan en póker\nn_poker <- comboCount(4,4) * comboCount(48, 1) * 13\np_poker <- n_poker / n_total_de_manos\n\ncat(\"\\nposibles arreglos de 5 cartas que resultan en póker: \", n_poker, \"\\n\")\n\n\nposibles arreglos de 5 cartas que resultan en póker:  624 \n\ncat(\"Probabilidad de tener algún póker: \", n_poker / n_total_de_manos, \"\\n\")\n\nProbabilidad de tener algún póker:  0.000240096 \n\n\n¿Qué tan probable es sacar póker de aces?\n\n# El póker de ases es solo 1 de los 13 posibles\nn_poker_as <- n_poker / 13\ncat(\"posibles arreglos de 5 cartas que resultan en póker de ases: \", n_poker_as, \"\\n\")\n\nposibles arreglos de 5 cartas que resultan en póker de ases:  48 \n\n# probabilidad de tener un póker de ases en un juego\np_poker_as <- n_poker_as / n_total_de_manos\ncat(\"Probabilidad de tener póker de ases: \", format(p_poker_as, scientific = F), \"\\n\")\n\nProbabilidad de tener póker de ases:  0.00001846893 \n\n\nFinalmente, ¿qué tan probable es conseguir dos vece póker de ases en una noche de juego?\n\n# sacar dos veces póker de ases entre las 15 partidas, suponiendo que las manos son independientes en cada juego.\ncat(\"Probabilidad de tener 2 veces póker de ases entre las 15 partidas: \", format(dbinom(2, size=15, prob=p_poker_as), scientific = F), \"\\n\")\n\nProbabilidad de tener 2 veces póker de ases entre las 15 partidas:  0.00000003580703 \n\n\nCon estos resultados, ¿qué piensas del “afortunado” jugador?\n\n\n\nEntre las críticas que se han hecho al procedimiento clásico de prueba de hipótesis está la que señala que el valor p, al excluir el valor de cero como valor plausible para el parámetro, no aporta información completa sobre los valores que sí son plausibles. Esto implica que la significancia estadística no implica relevancia práctica.¿Cómo interpretas esta afirmación?.\nEn el mismo razonamiento, un “valor de p extremadamente significativo” no hace otra cosa que excluir el cero como valor plausible para el parámetro no precisamente sobre la calidad del hallazgo.\nOtra crítica señala que interpretar el valor p en términos de evidencia en contra de la hipótesis nula (siguiendo el pensamiento de Fisher) o la plausibilidad de que la hipótesis nula sea falsa a veces se expresan equivocadamente como la probabilidad de que la hipótesis nula sea falsa en consideración de la evidencia (E) disponible. Al plantearlo así, formalmente se enuncia como \\(P(H_{0}|E)\\). Pero esto no es apropiado, es una incosnsistencia en la lógica del planteamiento.\n¿Puedes reconocer esta inconsistencia?\nLa inconsistencia está en que, en primer lugar como dije arriba, el valor p se define dentro del marco frecuentista y se concibe que los parámetros son valores constantes, aunque desconocidos (¡supuesto estadístico de efectos fijos!). No se trata de los parámetros de alguna distribución de probabilidades (observada o no). Por tanto, no tiene sentido asignar probabilidades a los distintos valores estimados del parámetro.\nAdemás, el valor p se calcula bajo el supuesto de que la hipótesis nula es cierta; esto hace imposible, por construcción, interpretarlo como la probabilidad de que la hipótesis alternativa sea cierta.\n¿Puedes comentar esto a la luz del ejemplo de la noche de cartas?\nLa probabilidad a la que se refiere el valor p guarda más relación con la probabilidad inversa, \\(P(E|H{0})\\). Esto se conoce como la verosimilitud, es decir, la probabilidad de observar los datos que se han obtenido en un estudio, los que entonces conviene valorar como condicionales a los supuestos hechos en el modelo estadístico y la hipótesis nula.\nLa probabilidad que realmente interesa -por ejemplo, al investigador de nuestro ejemplo- es la anteriormente mencionada \\(P(H_{0}|E)\\). Aunque no está definida dentro del marco frecuentista, en el marco Bayesiano sí se define. Las probabilidades \\(P(E|H_{0})\\) y \\(P(H_{0}|E)\\) no son iguales, pero,\n¿recuerdas qué representa cada uno de ellas? ¿cuál es la relación entre ambas?\nOtra crítica interesante surge de la llamada paradoja de Lindley (1957), quien mostró, con una formulación Bayesiana, que existe la posibilidad de tener datos congruentes con rechazar una hipótesis nula con un bajo valor p y que al mismo tiempo llevan a una probabilidad posterior alta.\nEncontró que es perfectamente posible, a partir de los mismos datos E, obtener al mismo tiempo una \\(P(E|H_{0})\\) = 0.05 (baja probabilidad de obtener una muestra como la que se observó, si \\(H_{0}\\) fuera cierta) y \\(P(H_{0}|E)\\) = 0.95 (fuerte evidencia en favor de \\(H_{0}\\)). Este resultado contradictorio pone en duda la validez de la interpretación del valor p como “evidencia en contra de la hipótesis nula”.\nSe ha contrargumentado que la paradoja requiere muestras grandes para manifestarse, y se oponen a los supuestos adicionales que requiere el análisis Bayesiano. Se ha argumentado que bajo condiciones razonables, un bajo valor p generalmente implica una baja probabilidad posterior, es decir, poca evidencia para la hipótesis nula. Sin embargo, a pesar de esta defensa al enfoque clásico, se ha encontrado que los valores p sistemáticamente sobreestiman la evidencia en contra de la hipótesis nula.\nEn resumen, el valor mismo de p, resultado de una prueba clásica de hipóteis, no aporta mucha información de interés para los investigadores. En caso de aceptar la hipótesis nula no se propicia llegar a ninguna conclusión sustancial.\nHay que tener claro que si el valor p es significativo, únicamente nos inclina a excluir un solo valor como estimador plausible para el parámetro.\nPeor aún, el significado de plausible en la última expresión tiene una relación nebulosa con la probabilidad que sí le interesa a los investigadores: la probabilidad posterior de que la hipótesis del estudio sea cierta a la luz de la evidencia recopilada \\(P(H_{0}|E)P\\).\n¿Qué piensas de la paradoja de Lindley y sus implicaciones\n\n\n\nPara enfrentar algunos de los inconvenientes del enfoque clásico de prueba de hipótesis se ha recomendado ahora sustituir el valor p por un intervalo de confianza que abarca un conjunto de valores que permiten valorar si es razonable rechazar la hipótesis nula y además, en caso contrario proporciona una gama de valores que caracterizan al parámetro, lo que resulta de mucho interés.\nLa práctica de presentar intervalos de confianza, posiblemente en conjunto con p, constituye una respuesta a la crítica de que sólo se excluye un valor como valor plausible para el parámetro. Además, hacer esto proporciona información sobre significancia. Si el intervalo no incluye el valor de cero, entonces se declararía el resultado como estadísticamente significativo. El intervalo informa también sobre el posible tamaño del efecto.\nA la luz de las críticas, Muchos autores ven necesario actualmente adoptar el marco Bayesiano para enfrentar las deficiencias del enfoque clásico.\n\n\n\nEn la práctica, la potencia de la prueba depende del grado de dispersión en los datos. Si se está asumiendo un modelo de probabilidades Gaussiano (distribución normal), el factor de disperción o escala se relaciona con la varianza. Por lo tanto, es usual notar que el mismo cálculo del error estandar, \\(s_{e}=\\frac{\\sigma}{\\sqrt{n}}\\), sugiere la solución.\n\n\nSe puede incrementar el tamaño de muestra, n, ¿por qué funcionaría esto?\nAumentar la precisión con la que se estima \\(\\sigma^2\\), ¿cómo se puede hacer esto?\n\nEs interesante apreciar, que la búsqueda de un tamaño de muestra apropiado para un estudio que estemos planeando, se puede lograr muy eficazmente haciendo simulaciones como las que hemos estado viendo en este bloque del curso. A través de este camino y haciendo el esfuerzo de especificar hipótesis alternativas relevantes se pueden resover preguntas como:\n\n¿Cuál es el tamaño de muestra necesario para detectar una cierta diferencia en lo que medimos?\n¿Cuál es la diferencia detectable dada una n o una potencia de la prueba (\\(1-\\beta\\))?\n¿Cuál es la potencia (\\(1-\\beta\\)) dado un n y cierta diferencia con \\(H_{a}\\) de interés?"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Bienvenidos al Módulo III de estadística",
    "section": "",
    "text": "Esta es la presentación del módulo III. Durante las últimas semanas revisaron conceptos de probabilidad y matemáticas, que necesitamos como un lenguaje eficiente de comunicación. También empezaron a explorar como es que se pueden analizar proposiciones sobre la existencia de asociación o incluso relaciones de dependencia entre dos variables: modelos de regresión simple. Ahora vamos aplicar y extender estos conocimientos para abordar el desafío de obtener conocimiento que nos permita comprender como funciona el mundo."
  }
]